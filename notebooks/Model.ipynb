{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11449575-6314-4708-9193-b279891e836c",
   "metadata": {},
   "source": [
    "## Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f302c0d-40f1-4bac-bf57-df54c89e72f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 24 13:42:44 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    39W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ee382-8c34-4130-99d3-80d5abdfbf1a",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d150586-d672-4999-9a7f-743a7d0d3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2664559-8789-4785-83d6-26327fe5ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpdmcndn60\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpdmcndn60/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09a35d4-17a4-437a-ad75-cfdbf9215827",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef863cc-4128-49a3-a156-fbdc859a9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from dataloader import BEDataset, BEDataModule\n",
    "import token_learner\n",
    "from transformer import PositionalEncoder,TransformerDecoder, generate_masks\n",
    "\n",
    "from film_layers import FiLMBlockV2, FiLMEncoder, ResBlockDWConv\n",
    "from rt1 import RT1Encoder\n",
    "from utils.model_utils import TextEncoder, ImageFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b26cc-b5a8-4a5a-9e6c-6d2721d34c58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e68541d-e1c2-48df-a18d-c37c9da42002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>in_state</th>\n",
       "      <th>goal_state</th>\n",
       "      <th>action_description</th>\n",
       "      <th>motor_cmd</th>\n",
       "      <th>len_action_desc</th>\n",
       "      <th>len_motor_cmd</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7294</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>put the fork to the right of buttermilk</td>\n",
       "      <td>:FORK GREEN POSE-9 :BUTTERMILK GREEN POSE-2 :F...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>move the bottle backwards</td>\n",
       "      <td>:BOTTLE RED POSE-2 :BOTTLE  #'*backward-transf...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4235</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>put the bottle to the left of breakfast-cereal</td>\n",
       "      <td>:BOTTLE RED POSE-7 :BREAKFAST-CEREAL BLUE POSE...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6990</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>put the milk in front of bottle</td>\n",
       "      <td>:MILK BLUE POSE-8 :BOTTLE RED POSE-4 :MILK  #'...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7096</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>put the cup in front of glasses</td>\n",
       "      <td>:CUP GREEN POSE-6 :GLASSES RED POSE-2 :CUP  #'...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_ID  in_state  goal_state  \\\n",
       "0       7294         0          10   \n",
       "1        405         0           8   \n",
       "2       4235         0          10   \n",
       "3       6990         0          10   \n",
       "4       7096         0          10   \n",
       "\n",
       "                               action_description  \\\n",
       "0         put the fork to the right of buttermilk   \n",
       "1                       move the bottle backwards   \n",
       "2  put the bottle to the left of breakfast-cereal   \n",
       "3                 put the milk in front of bottle   \n",
       "4                 put the cup in front of glasses   \n",
       "\n",
       "                                           motor_cmd  len_action_desc  \\\n",
       "0  :FORK GREEN POSE-9 :BUTTERMILK GREEN POSE-2 :F...                8   \n",
       "1  :BOTTLE RED POSE-2 :BOTTLE  #'*backward-transf...                4   \n",
       "2  :BOTTLE RED POSE-7 :BREAKFAST-CEREAL BLUE POSE...                8   \n",
       "3  :MILK BLUE POSE-8 :BOTTLE RED POSE-4 :MILK  #'...                7   \n",
       "4  :CUP GREEN POSE-6 :GLASSES RED POSE-2 :CUP  #'...                7   \n",
       "\n",
       "   len_motor_cmd version  \n",
       "0             11      v2  \n",
       "1              8      v1  \n",
       "2             11      v2  \n",
       "3             11      v2  \n",
       "4             11      v2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(os.path.join(config.DATASET_PATH, \"train.csv\"))\n",
    "\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7cd7ee-95e6-450a-b7bf-35a626daf357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building data object\n",
    "ds = BEDataset(\n",
    "    df=csv    \n",
    ")\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ccf421-7092-4d19-b7a8-84d4864f34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  4876\n",
      "====================================================================================================\n",
      "ID\t:  9401\n",
      ">> InState\t:  torch.Size([3, 224, 224])\n",
      ">> Desc\t:\n",
      "{'ids': tensor([  101,  2404,  1996,  5442,  2000,  1996,  2157,  1997, 12256, 17130,\n",
      "         2378,   102,     0,     0,     0,     0]),\n",
      " 'length': 8,\n",
      " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]),\n",
      " 'raw': 'put the knife to the right of mondamin',\n",
      " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
      ">> Cmd\t:\n",
      "{'ids': tensor([ 0, 17, 41, 30, 18, 41, 36, 17, 48, 18,  2,  2,  2,  2,  2,  2]),\n",
      " 'length': 11,\n",
      " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
      " 'raw': ':KNIFE GREEN POSE-10 :MONDAMIN GREEN POSE-3 :KNIFE  '\n",
      "        \"#'*rightward-transformation*  :MONDAMIN\"}\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# fetching example\n",
    "rand_idx = np.random.randint(low=0, high=len(ds))\n",
    "ex = ds[rand_idx]\n",
    "\n",
    "print(\"Dataset size: \", len(ds))\n",
    "print(\"=\"*100)\n",
    "print(\"ID\\t: \", ex[\"sample_id\"])\n",
    "print(\">> InState\\t: \", ex[\"in_state\"].shape)\n",
    "print(\">> Desc\\t:\")\n",
    "pprint(ex[\"action_desc\"])\n",
    "print(\">> Cmd\\t:\")\n",
    "pprint(ex[\"motor_cmd\"])\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425b526-43d7-483b-b3bc-02028bfb4b7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820bb68f-3341-4d6e-9cea-80dbdf2de002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # examples: 4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on 3610 samples.\n",
      "INFO:root:Validating on 1266 samples.\n"
     ]
    }
   ],
   "source": [
    "dm = BEDataModule()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "383eaa10-47d7-4620-928e-8fbcd6889d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*100)\n",
    "# logging.info(\"\\n>> train data loader\")\n",
    "# print(f\"# train batches\\t: {len(dm.train_dataloader())}\")\n",
    "# for data in dm.train_dataloader():\n",
    "#     # pprint(data)\n",
    "#     sample_id, in_state, ad, cmd = data[\"sample_id\"], data[\"in_state\"], data[\"action_desc\"], data[\"motor_cmd\"]\n",
    "#     print(\"In \\t\\t\\t: \", in_state.shape)\n",
    "#     print(\"Action desc \\t\\t: \", ad[\"ids\"].shape)\n",
    "#     print(\"Action desc (len) \\t: \", ad[\"length\"].shape)\n",
    "#     print(\"CMD \\t\\t\\t: \", cmd[\"ids\"].shape)\n",
    "#     print(\"CMD(len) \\t\\t: \", cmd[\"length\"].shape)\n",
    "#     break\n",
    "\n",
    "# print(\"\\nIDs & decided tokens\")\n",
    "# for data in dm.train_dataloader():\n",
    "#     print(data[\"action_desc\"][\"ids\"][0].tolist())\n",
    "#     print(dm.train_ds._decode_inputs(data[\"action_desc\"][\"ids\"][0].tolist()))\n",
    "#     print()\n",
    "#     print(data[\"motor_cmd\"][\"ids\"][0].tolist())\n",
    "#     print(dm.train_ds._decode_outputs(data[\"motor_cmd\"][\"ids\"][0].tolist()))\n",
    "\n",
    "#     break\n",
    "    \n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bfcb6-3d67-4d4a-934d-95af834e1a07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Fetch batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c22a7a-16f8-4411-8839-8b724fc29869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 1.49 s, total: 2.72 s\n",
      "Wall time: 12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sample = next(iter(dm.train_dataloader()))\n",
    "sample[\"in_state\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b32ff7-02ee-4fa3-b3b9-7885f558072b",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bcf1ad-8562-458b-b07c-226d1ed3dbe0",
   "metadata": {},
   "source": [
    "<!-- ![RT1 model architecture](../../imgs/rt1+.png) -->\n",
    "<center>\n",
    "    <img src=\"../imgs/rt1+.png\" alt=\"RT1 model architecture\" width=\"300\" height=\"400\">\n",
    "\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cea30-c012-4a53-a94b-7651270e4c38",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d547d-b935-42b3-bafa-ded2cddaec51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe10a4-0a68-429f-a18c-dfb4012920ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# te = TextEncoder(freeze=True).cuda()\n",
    "# summary(model=te, col_names=[\"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790e904-591d-4ee3-8ae3-f9ee204dbe31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# emb = te(\n",
    "#     inp_ids=sample[\"action_desc\"][\"ids\"].cuda(),\n",
    "#     mask=sample[\"action_desc\"][\"mask\"].cuda(),\n",
    "#     tok_type_ids=sample[\"action_desc\"][\"token_type_ids\"].cuda()\n",
    "# )\n",
    "\n",
    "# emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491611ae-2f70-404b-b04c-a401bad6fc56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test Img Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d73ba-efef-4d32-81cb-520974830c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fe = ImageFeatureExtractor(pretrained=True, arch=\"resnet34\").cuda()\n",
    "\n",
    "# summary(fe, col_names=[\"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9d6e5-ca31-4b20-8fe1-07412fcb4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ftrs = fe(sample[\"in_state\"].cuda())\n",
    "\n",
    "# img_ftrs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea6fe0-fc93-4c1d-9f7d-ae8194f9bb29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test FiLM Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b8d53-a51d-4dfd-9cd6-0dabc3e1b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# film_block = FiLMBlockV2().cuda()\n",
    "# print(film_block)\n",
    "# summary(model=film_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a5658-8b44-4fd9-8a3e-e2c3f2380864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_cond_ftrs = film_block(\n",
    "#     img_features=img_ftrs, \n",
    "#     conditioning=emb\n",
    "# )\n",
    "\n",
    "# text_cond_ftrs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e75562-714a-480f-9b03-be898c3aebd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test Residual FiLM Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca31d01-12cd-4fbf-af23-1dbecfe2b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dw_res = ResBlockDWConv(512, 512).cuda()\n",
    "# summary(model=dw_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cd288-29c5-41ef-be96-72a066bfbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_cond_ftrs_res = dw_res(\n",
    "#     img_features=img_ftrs, \n",
    "#     conditioning=emb\n",
    "# )\n",
    "\n",
    "# text_cond_ftrs_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00506f45-07c7-40fc-927c-3e307e91b23f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test FiLM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a904d1-b1ef-40b2-9344-f2580105ee41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# film_encoder = FiLMEncoder(\n",
    "#     arch=\"resnet34\",\n",
    "#     n_res_blocks=6,\n",
    "# ).cuda()\n",
    "\n",
    "# # print(film_encoder)\n",
    "# summary(model=film_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70f6a7-c6b5-4743-8ecf-9cfa122dd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# out = film_encoder(\n",
    "#     x= sample[\"in_state\"].cuda(),\n",
    "#     conditioning= emb\n",
    "# )\n",
    "\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217cc28-4eb7-4f76-86ee-51dd6ae8f248",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Token Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2da760-c2ee-4ff1-97bd-8859562a484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, C, H_W = out.shape\n",
    "# N, C, H_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb960649-ad52-4a6f-be9a-279263b0ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokL_v11 = token_learner.TokenLearnerModuleV11(feature_shape=(N, H_W, C)).cuda()\n",
    "# print(tokL_v11)\n",
    "# summary(model=tokL_v11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43cec1-32e2-4f1d-bb5a-3ba026a57fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learned_tokens = tokL_v11(out.view(N, H_W, C))\n",
    "# learned_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e045e3a-4d75-454a-9fdd-c5205f332a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21ce81c2-ecfd-49cf-8613-b806d585dfb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RT-1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d56dd9db-abff-4cb9-b8af-b1b68e3e7ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Param #                   Trainable\n",
       "==============================================================================================================\n",
       "RT1Encoder                                                   --                        Partial\n",
       "├─TextEncoder: 1-1                                           --                        False\n",
       "│    └─BertModel: 2-1                                        --                        False\n",
       "│    │    └─BertEmbeddings: 3-1                              (15,891,456)              False\n",
       "│    │    └─BertEncoder: 3-2                                 (12,609,536)              False\n",
       "│    │    └─BertPooler: 3-3                                  (262,656)                 False\n",
       "│    └─Dropout: 2-2                                          --                        --\n",
       "├─FiLMEncoder: 1-2                                           --                        Partial\n",
       "│    └─ImageFeatureExtractor: 2-3                            --                        Partial\n",
       "│    │    └─ResNet: 3-4                                      21,797,672                Partial\n",
       "│    │    └─Sequential: 3-5                                  (21,284,672)              False\n",
       "│    └─ModuleList: 2-4                                       --                        True\n",
       "│    │    └─ResBlockDWConv: 3-6                              1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-7                              1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-8                              1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-9                              1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-10                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-11                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-12                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-13                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-14                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-15                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-16                             1,056,768                 True\n",
       "│    │    └─ResBlockDWConv: 3-17                             1,056,768                 True\n",
       "├─TokenLearnerModuleV11: 1-3                                 --                        True\n",
       "│    └─LayerNormalization: 2-5                               --                        True\n",
       "│    │    └─LayerNorm: 3-18                                  1,024                     True\n",
       "│    └─FeedFowardLayer: 2-6                                  --                        True\n",
       "│    │    └─Linear: 3-19                                     32,832                    True\n",
       "│    │    └─GELU: 3-20                                       --                        --\n",
       "│    │    └─Linear: 3-21                                     520                       True\n",
       "│    │    └─Dropout: 3-22                                    --                        --\n",
       "==============================================================================================================\n",
       "Total params: 84,561,584\n",
       "Trainable params: 13,228,592\n",
       "Non-trainable params: 71,332,992\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = RT1Encoder(cnn_bacnbone=\"resnet34\").to(config.DEVICE)\n",
    "summary(model=encoder, col_names=[\"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7405de1c-ea97-4908-aa25-7858478627c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.7 ms, sys: 34.8 ms, total: 91.5 ms\n",
      "Wall time: 7.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 8])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "src_enc, tokens = encoder(\n",
    "    input_ids=sample[\"action_desc\"][\"ids\"].cuda(),\n",
    "    attn_mask=sample[\"action_desc\"][\"mask\"].cuda(),\n",
    "    token_type_ids=sample[\"action_desc\"][\"token_type_ids\"].cuda(),\n",
    "    imgs=sample[\"in_state\"].cuda()\n",
    ")\n",
    "\n",
    "src_enc.shape, tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e620f-5541-4a49-acdf-43ec4b3cce02",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2c336-d441-4f0d-a879-e4337d2abc7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Transformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5ebf21e-d456-4f85-bb0c-fd1056c517f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "TransformerDecoder                       --\n",
       "├─Embedding: 1-1                         26,624\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─TransformerDecoderLayer: 2-1      --\n",
       "│    │    └─MultiHeadAttention: 3-1      1,049,088\n",
       "│    │    └─LayerNorm: 3-2               1,024\n",
       "│    │    └─MultiHeadAttention: 3-3      1,049,088\n",
       "│    │    └─LayerNorm: 3-4               1,024\n",
       "│    │    └─Sequential: 3-5              2,099,712\n",
       "│    │    └─LayerNorm: 3-6               1,024\n",
       "│    │    └─Dropout: 3-7                 --\n",
       "│    └─TransformerDecoderLayer: 2-2      --\n",
       "│    │    └─MultiHeadAttention: 3-8      1,049,088\n",
       "│    │    └─LayerNorm: 3-9               1,024\n",
       "│    │    └─MultiHeadAttention: 3-10     1,049,088\n",
       "│    │    └─LayerNorm: 3-11              1,024\n",
       "│    │    └─Sequential: 3-12             2,099,712\n",
       "│    │    └─LayerNorm: 3-13              1,024\n",
       "│    │    └─Dropout: 3-14                --\n",
       "│    └─TransformerDecoderLayer: 2-3      --\n",
       "│    │    └─MultiHeadAttention: 3-15     1,049,088\n",
       "│    │    └─LayerNorm: 3-16              1,024\n",
       "│    │    └─MultiHeadAttention: 3-17     1,049,088\n",
       "│    │    └─LayerNorm: 3-18              1,024\n",
       "│    │    └─Sequential: 3-19             2,099,712\n",
       "│    │    └─LayerNorm: 3-20              1,024\n",
       "│    │    └─Dropout: 3-21                --\n",
       "│    └─TransformerDecoderLayer: 2-4      --\n",
       "│    │    └─MultiHeadAttention: 3-22     1,049,088\n",
       "│    │    └─LayerNorm: 3-23              1,024\n",
       "│    │    └─MultiHeadAttention: 3-24     1,049,088\n",
       "│    │    └─LayerNorm: 3-25              1,024\n",
       "│    │    └─Sequential: 3-26             2,099,712\n",
       "│    │    └─LayerNorm: 3-27              1,024\n",
       "│    │    └─Dropout: 3-28                --\n",
       "│    └─TransformerDecoderLayer: 2-5      --\n",
       "│    │    └─MultiHeadAttention: 3-29     1,049,088\n",
       "│    │    └─LayerNorm: 3-30              1,024\n",
       "│    │    └─MultiHeadAttention: 3-31     1,049,088\n",
       "│    │    └─LayerNorm: 3-32              1,024\n",
       "│    │    └─Sequential: 3-33             2,099,712\n",
       "│    │    └─LayerNorm: 3-34              1,024\n",
       "│    │    └─Dropout: 3-35                --\n",
       "│    └─TransformerDecoderLayer: 2-6      --\n",
       "│    │    └─MultiHeadAttention: 3-36     1,049,088\n",
       "│    │    └─LayerNorm: 3-37              1,024\n",
       "│    │    └─MultiHeadAttention: 3-38     1,049,088\n",
       "│    │    └─LayerNorm: 3-39              1,024\n",
       "│    │    └─Sequential: 3-40             2,099,712\n",
       "│    │    └─LayerNorm: 3-41              1,024\n",
       "│    │    └─Dropout: 3-42                --\n",
       "=================================================================\n",
       "Total params: 25,232,384\n",
       "Trainable params: 25,232,384\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = TransformerDecoder().cuda()\n",
    "summary(model=dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4eab8990-184b-4854-980e-ef4887300b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: torch.Size([8, 1, 1, 512]) - k: torch.Size([8, 1, 1, 512]) - v: torch.Size([8, 1, 1, 512]) \n",
      "q: torch.Size([8, 8, 1, 512]) - k: torch.Size([8, 512, 8]) - v: torch.Size([8, 512, 8]) \n",
      "mask: torch.Size([8, 16, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4096x8 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m \u001b[43mdec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmotor_cmd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/miniconda3/envs/smf_be/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/repo/smf_be/notebooks/../src/transformer.py:274\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, src, encoder_outputs, y, src_mask, y_mask)\u001b[0m\n\u001b[1;32m    272\u001b[0m     src, y_mask \u001b[38;5;241m=\u001b[39m generate_masks(src, y)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 274\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/miniconda3/envs/smf_be/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/repo/smf_be/notebooks/../src/transformer.py:228\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, src, encoder_outputs, y, src_mask, y_mask)\u001b[0m\n\u001b[1;32m    226\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(src)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Multi-head attention over encoder outputs\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m multihead_attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Apply dropout and add the residual connection\u001b[39;00m\n\u001b[1;32m    230\u001b[0m src \u001b[38;5;241m=\u001b[39m src \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(multihead_attn_output)\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/miniconda3/envs/smf_be/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/repo/smf_be/notebooks/../src/transformer.py:84\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Linear calculation +  split into num_heads\u001b[39;00m\n\u001b[1;32m     83\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_q(q)\u001b[38;5;241m.\u001b[39mview(input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k) \u001b[38;5;66;03m# (B, L, num_heads, d_k)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k) \u001b[38;5;66;03m# (B, L, num_heads, d_k)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_v(v)\u001b[38;5;241m.\u001b[39mview(input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k) \u001b[38;5;66;03m# (B, L, num_heads, d_k)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# For convenience, convert all tensors in size (B, num_heads, L, d_k)\u001b[39;00m\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/miniconda3/envs/smf_be/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ocean/projects/cis230036p/cmanouan/miniconda3/envs/smf_be/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4096x8 and 512x512)"
     ]
    }
   ],
   "source": [
    "dec_out = dec(\n",
    "    src=src_enc, \n",
    "    encoder_outputs=tokens,\n",
    "    y=None #sample[\"motor_cmd\"][\"ids\"].cuda()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f252ad6-5c3a-44ce-ab3d-4d4d75d1960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e365900-13ff-4dd8-b789-6f45b15c0564",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Action Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "929f0bc4-3be4-4b84-a52a-7235e9af947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model:int=config.D_MODEL, \n",
    "        vocab_size:int=len(config.TARGETS)\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = nn.Linear(in_features=d_model, out_features=vocab_size)\n",
    "        self._softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self._softmax(self.proj(tokens))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9fef7ba-432f-448c-bac6-c3651e1f1203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionGenerator(\n",
      "  (proj): Linear(in_features=512, out_features=52, bias=True)\n",
      "  (_softmax): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ActionGenerator                          --\n",
       "├─Linear: 1-1                            26,676\n",
       "├─LogSoftmax: 1-2                        --\n",
       "=================================================================\n",
       "Total params: 26,676\n",
       "Trainable params: 26,676\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = ActionGenerator().cuda()\n",
    "print(generator)\n",
    "summary(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1013f117-e5e3-4b2c-b14b-d2260e40f351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 512, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, C, T = tokens.shape\n",
    "\n",
    "N, C, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce3a76ea-ae3b-403a-b8e2-a817f50498fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 52])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = generator(tokens.view(N, T, C))\n",
    "\n",
    "actions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14293b-b031-477b-a643-3811927b1bb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RT-1 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ec749-1fbf-4072-b191-b6e3ad2f243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RT1Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.positional_encoder = PositionalEncoder()\n",
    "        self.transformer = TransformerDecoder()\n",
    "        # \n",
    "        self.action_generator = ActionGenerator()\n",
    "        \n",
    "\n",
    "    def _positional_encoding(\n",
    "        self,\n",
    "        seq, \n",
    "        dim, \n",
    "        temperature = 10000, \n",
    "        device = None, \n",
    "        dtype = torch.float32\n",
    "    ):\n",
    "        n = torch.arange(seq, device = device)\n",
    "        omega = torch.arange(dim // 2, device = device) / (dim // 2 - 1)\n",
    "        omega = 1. / (temperature ** omega)\n",
    "\n",
    "        n = n[:, None] * omega[None, :]\n",
    "        pos_emb = torch.cat((n.sin(), n.cos()), dim = 1)\n",
    "        \n",
    "        return pos_emb.type(dtype)\n",
    "\n",
    "    \n",
    "    def forward(self, instructions, imgs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f893fa-9324-4244-aad2-a66db2243700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cde5f94-8a3c-458d-94da-9655d7ddb2d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RT-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033aac5-7312-47d8-8ff8-8044ebb2fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RT1(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = RT1Encder()\n",
    "        self.decoder = RT1Decoder()\n",
    "        \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids, imgs):\n",
    "        \n",
    "        tokens = self.encode(input_ids, attn_mask, token_type_ids, imgs)\n",
    "        out = self.decode(tokens, )\n",
    "    \n",
    "    def encode(self, input_ids, attn_mask, token_type_ids, imgs):\n",
    "        return self.encoder(input_ids, attn_mask, token_type_ids, imgs)\n",
    "    \n",
    "    def decode(self, enc_outputs, x_mask, y, y_mask):\n",
    "        return self.decoder(y, enc_outputs, src_mask, tgt_mask)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        pass\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def compute_loss(self, outputs, targets):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fd461-7028-49de-bcb9-e8464433f548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a346bbe-d174-40a9-a807-e2cd63665ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bebcb-a94a-4272-b68d-5eeee9dbd638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMF-BE",
   "language": "python",
   "name": "smf-be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
