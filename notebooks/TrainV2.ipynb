{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51054b27-9fd9-4a34-9c80-9519b2fb3060",
   "metadata": {},
   "source": [
    "## ü§î Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d77a40d-8e01-420e-b572-fe22bd600f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 16 00:21:51 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              44W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f74170-ded5-4ca1-81b1-7b3857810090",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üõ†Ô∏è Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ff9e3c-a68b-4a84-ab94-c2cd07294dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0920d519-4636-47e0-977c-c0d6583ba014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import RichProgressBar, TQDMProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "import math\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import time\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ae7b8b-5631-4c2b-a735-43e3cee5cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec61ddc-e278-454c-b6ec-538359e04c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from dataloader import BEDataset, BEDataModule\n",
    "from transformer import make_attn_mask\n",
    "\n",
    "from rt1 import RT1CRAM\n",
    "from utils.model_utils import plot_attention, fetch_sample_from_batch\n",
    "import utils.data_utils as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79af0e-70f8-4b36-b69a-b25466aa88b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìä Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df6190a-d007-4387-b470-f7ea1063f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on 3848 samples.\n",
      "INFO:root:Validating on 660 samples.\n",
      "INFO:root:Testing on 250 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # examples: 4758\n"
     ]
    }
   ],
   "source": [
    "dm = BEDataModule()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c0210-17c3-4054-af37-3658ddc4799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sample_id', 'in_state', 'action_desc', 'motor_cmd'])\n",
      "CPU times: user 533 ms, sys: 552 ms, total: 1.09 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 288, 288])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(batch.keys())\n",
    "batch[\"in_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a67f8e-a0b6-45a6-ae7d-436fbdf2a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = fetch_sample_from_batch(\n",
    "    batch, \n",
    "    batch_size=batch[\"in_state\"].shape[0],\n",
    "    random=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83167c52-6966-4526-aa0b-24dd32fb3bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sample_id', 'in_state', 'raw_action_desc', 'ids', 'mask', 'token_type_ids', 'raw_motor_cmd', 'decoder_inp_ids', 'labels'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1310ecd6-96ac-47af-bc49-dc2d60186624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] put the milk to the left of bowl [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_ds.tokenizer.decode(batch[\"action_desc\"][\"ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97482fdb-fe8a-4c52-9f46-2f02e8d12704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put the milk to the left of bowl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"action_desc\"][\"raw\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ff744-12e8-4052-9d4b-df1c92b76390",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ü§ñ RT1-CRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f735344-d5e5-4193-a4f8-bde3804622fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b3.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b3.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "RT1CRAM                                                           --\n",
       "‚îú‚îÄRT1Encoder: 1-1                                                 --\n",
       "‚îÇ    ‚îî‚îÄTextEncoder: 2-1                                           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBertModel: 3-1                                        (28,763,648)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-2                                          --\n",
       "‚îÇ    ‚îî‚îÄFiLMEncoder: 2-2                                           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄImageFeatureExtractor: 3-3                            10,300,456\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4                                       4,227,072\n",
       "‚îÇ    ‚îî‚îÄTokenLearnerV11: 2-3                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-5                                       134,408\n",
       "‚îú‚îÄRT1Decoder: 1-2                                                 --\n",
       "‚îÇ    ‚îî‚îÄTransformerDecoder: 2-4                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbeddingLayer: 3-6                                   53,248\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-7                                       3,154,432\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-5                                             1,024\n",
       "‚îÇ    ‚îî‚îÄActionGenerator: 2-6                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-8                                       26,676\n",
       "‚îú‚îÄCrossEntropyLoss: 1-3                                           --\n",
       "‚îú‚îÄCharErrorRate: 1-4                                              --\n",
       "‚îú‚îÄWordErrorRate: 1-5                                              --\n",
       "==========================================================================================\n",
       "Total params: 46,660,964\n",
       "Trainable params: 7,793,980\n",
       "Non-trainable params: 38,866,984\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt1 = RT1CRAM(\n",
    "    cnn_bacnbone=config.SELECTED_CNN_BACKBONE, \n",
    "    num_res_blocks=config.NUM_RES_BLOCKS,\n",
    "    freeze_cnn_backbone=config.FREEZE_CNN\n",
    ").cuda()\n",
    "# print(rt1)\n",
    "\n",
    "summary(model=rt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe02812-d0e2-4a8a-b562-af007ef094be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üèãÔ∏è‚Äç Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d9d22df-8a7b-4cba-8811-dd0bd796815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    initial_lr: 1.0\n",
       "    lr: 1e-05\n",
       "    maximize: False\n",
       "    weight_decay: 2e-06\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    ignore_index=config.TGT_PAD_TOK_ID, \n",
    "    label_smoothing=config.LABEL_SMOOTHING\n",
    ")\n",
    "\n",
    "opt = getattr(torch.optim, config.OPTIMIZER)(\n",
    "    params=[p for p in rt1.parameters() if p.requires_grad], \n",
    "    lr=config.LR,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = getattr(torch.optim.lr_scheduler, config.LR_SCHEDULER[\"type\"])(**config.LR_SCHEDULER[\"params\"], optimizer=opt)\n",
    "\n",
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebc75f-ee27-4698-a552-c63d2ad0e813",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989aec1b-f692-4e0b-99ab-9fc7c97a38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch, loss_fn):\n",
    "\n",
    "    input_ids=batch[\"action_desc\"][\"ids\"].to(config.DEVICE)\n",
    "    attn_mask=batch[\"action_desc\"][\"mask\"].to(config.DEVICE)\n",
    "    token_type_ids=batch[\"action_desc\"][\"token_type_ids\"].to(config.DEVICE)\n",
    "    imgs=batch[\"in_state\"].to(config.DEVICE)\n",
    "    decoder_inp=batch[\"motor_cmd\"][\"decoder_inp_ids\"].to(config.DEVICE)\n",
    "    \n",
    "    # forward\n",
    "    logits, self_attn_ws, cross_attn_ws = model(\n",
    "        input_ids=input_ids, \n",
    "        attn_mask=attn_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        imgs=imgs,\n",
    "        decoder_inp=decoder_inp\n",
    "    )\n",
    "\n",
    "    # loss computation\n",
    "    labels = batch[\"motor_cmd\"][\"labels\"].to(config.DEVICE)\n",
    "    loss = loss_fn(logits.view(-1, logits.shape[2]), labels.view(-1))\n",
    "        \n",
    "    return loss, logits, self_attn_ws, cross_attn_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04dc1802-3a45-4e35-b8d5-cd93af2d509d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss, logits, self_attn_ws, cross_attn_ws = training_step(model=rt1, batch=batch, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac328b89-071d-4e8c-ad24-541a87a419c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 52])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e660617-728a-4183-a429-64ecfd8fcec3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 16]),\n",
       " tensor([[19, 44, 42, 44, 42, 27,  9, 40, 49, 34, 44, 43, 43, 19,  6, 43],\n",
       "         [44, 32, 14, 11, 40, 27, 40, 44, 46, 43, 26, 19, 44, 36, 14, 14],\n",
       "         [32, 40, 32, 44, 27, 23, 46, 40,  8, 32, 19, 44,  6, 44,  8,  8],\n",
       "         [32,  6, 32, 26, 46, 48, 48, 44, 29, 34, 34, 44, 19,  8,  6, 17],\n",
       "         [14, 51, 30, 19,  8, 36, 14, 50, 40,  8, 34, 43, 33, 32, 32,  6],\n",
       "         [32, 27,  0, 47,  5, 28, 38, 27, 49, 22, 17, 44, 19, 19, 50, 19],\n",
       "         [34, 48, 44,  5, 48, 50, 34, 14, 44, 48, 22, 33,  6, 49, 44, 32],\n",
       "         [32, 14, 33, 50, 25,  1, 28, 43, 17, 17, 43,  6,  6,  8,  6, 19],\n",
       "         [14, 34, 44, 29, 17, 28, 42, 44, 34, 18, 43, 14, 43, 32, 32, 14],\n",
       "         [14, 14, 19, 32, 44, 28, 48, 25, 32, 50, 44, 32, 51, 19, 19, 14],\n",
       "         [32, 34, 19, 34, 50, 19, 11, 34, 34, 44, 44, 32, 11,  6, 17, 43],\n",
       "         [44, 44, 32, 34, 44, 19, 23, 46, 34, 50,  8,  8,  6,  6, 32, 35],\n",
       "         [32, 19, 45, 19,  5, 48, 38,  8,  5, 41, 19, 12, 32, 19, 32, 19],\n",
       "         [14, 27, 32, 36, 34, 11, 48, 34, 50, 34, 19, 17, 17, 49, 19, 19],\n",
       "         [32, 34, 32, 43, 21, 48, 11, 50, 34, 49, 34, 51, 21, 44, 39, 44],\n",
       "         [32, 19, 19, 14, 16, 19, 42,  8, 23, 43, 32, 19,  6, 19,  8,  6],\n",
       "         [32, 14, 30, 48, 44, 19, 47, 32,  8, 43, 26, 44, 43, 45, 45, 32],\n",
       "         [11, 44, 19, 29, 19, 29, 44, 44,  5, 50, 50, 11, 43, 19,  8, 47],\n",
       "         [25, 19,  6, 51, 14, 24, 25, 17, 17, 32, 50, 17, 19, 43, 43, 19],\n",
       "         [32, 14, 19, 43, 25, 23,  8, 33,  8, 33, 50, 32,  8,  6, 17, 19],\n",
       "         [14, 33, 44, 41, 40, 19,  6, 43, 24, 14, 43, 17,  6,  6, 43, 43],\n",
       "         [19, 14,  6, 14, 14, 34, 46, 17, 43, 43, 17, 22, 22,  8, 33, 32],\n",
       "         [44, 28, 48,  5, 25, 40, 44, 27, 43, 19, 43,  6, 36, 43, 27, 18],\n",
       "         [32, 41, 36, 41, 48, 50, 48, 47, 33, 33, 14, 19, 19, 25,  2, 19],\n",
       "         [32, 33, 19, 48, 14, 33, 49, 25, 38, 25, 35, 44, 43, 43,  6,  6],\n",
       "         [32, 34, 44,  6, 50, 51, 26, 48, 39, 44, 34, 35, 51, 32, 19, 51],\n",
       "         [25, 42, 42, 32, 18,  2, 50, 14,  1, 18, 43, 32, 43, 25, 32, 44],\n",
       "         [34, 19, 32,  8, 47, 42, 50,  5, 34, 24, 32,  6,  8,  6,  6, 34],\n",
       "         [ 1, 32, 34, 18, 32, 46, 14, 29, 19, 26,  6, 43,  6, 34,  6, 29],\n",
       "         [14, 34, 19, 33, 29, 28, 19, 34,  2, 34,  6,  6,  6, 48,  6, 19],\n",
       "         [40, 47, 19, 34, 19, 42, 34, 12, 38, 47, 43, 23, 50, 19, 43,  6],\n",
       "         [32, 34, 34, 32, 25, 48,  2, 49, 48, 44, 14, 26,  8, 43,  6, 29]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "preds = logits.softmax(dim=-1).argmax(dim=-1)\n",
    "preds.shape, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "201eb649-7cc6-4186-9c98-a8d6bef4aa07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\":MUG #'*forward-transformation* #'*on-transformation* #'*forward-transformation* #'*on-transformation* POSE-4 :GLASSES POSE-2 POSE-13 POSE-5 #'*forward-transformation* #'*leftward-transformation* #'*leftward-transformation* :MUG :SHOE #'*leftward-transformation*\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# decode predictions\n",
    "preds = rt1.decode_predictions(\n",
    "    predicted_ids=preds\n",
    ")\n",
    "\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4c4f32c-6280-481e-8b06-7416fcedc867",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (980487135.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    lonpkv;/ad\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lonpkv;/ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4bbf71-5c90-44de-abaf-679aeb45b0fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üõü Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ce1de8-a9ca-494a-ad5a-5e10b26eda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(\n",
    "    model:pl.LightningModule, \n",
    "    batch_inp:dict, \n",
    "    max_len:int=config.MAX_OUT_SEQ_LEN, \n",
    "    debug:bool=False\n",
    "):\n",
    "    if model.device.type == \"cpu\":\n",
    "        model.to(config.DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    sos_token = config.TARGETS_MAPPING[\"[SOS]\"]\n",
    "    eos_token = config.TARGETS_MAPPING[\"[EOS]\"]\n",
    "    \n",
    "    input_ids=batch_inp[\"ids\"].to(config.DEVICE)\n",
    "    attn_mask=batch_inp[\"mask\"].to(config.DEVICE)\n",
    "    token_type_ids=batch_inp[\"token_type_ids\"].to(config.DEVICE)\n",
    "    imgs=batch_inp[\"in_state\"].to(config.DEVICE)\n",
    "\n",
    "    _, learned_tokens = model._encode(\n",
    "        input_ids=input_ids, \n",
    "        attn_mask=attn_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        imgs=imgs    \n",
    "    )\n",
    "    \n",
    "    decoder_inp = torch.empty(1, 1, dtype=torch.long, device=input_ids.device).fill_(sos_token)\n",
    "\n",
    "    for t in range(config.MAX_OUT_SEQ_LEN):\n",
    "        mask = make_attn_mask(dim=decoder_inp.shape[1])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, self_attn_ws, cross_attn_ws = rt1._decode(\n",
    "            decoder_inp=decoder_inp, \n",
    "            encoder_out=learned_tokens,\n",
    "            attn_mask=mask,\n",
    "            return_actions=False\n",
    "        )\n",
    "\n",
    "        # perform greedy decoding\n",
    "        probs = rt1.decoder.action_generator(logits[:, -1])\n",
    "\n",
    "        _, next_tok = torch.max(probs, dim=-1)\n",
    "        # update decoder input\n",
    "        decoder_inp = torch.cat((decoder_inp, next_tok.unsqueeze(1)), dim=1)\n",
    "            \n",
    "    return decoder_inp[:, 1:].cpu().detach(), logits, self_attn_ws.cpu().detach(), cross_attn_ws.cpu().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d18fe0-8984-4cd7-b4ed-0be0ab6eae74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff9aedb-5a52-48f6-b8df-d2cff2439aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(batch, model, loss_fn, debug:bool=False):\n",
    "    \n",
    "    inp = fetch_sample_from_batch(\n",
    "        batch, \n",
    "        batch_size=batch[\"in_state\"].shape[0],\n",
    "        random=True\n",
    "    )\n",
    "    \n",
    "    pred_ids, logits, self_attn_ws, cross_attn_ws = greedy_decoding(\n",
    "        model=model, \n",
    "        batch_inp=inp, \n",
    "        debug=debug\n",
    "    )\n",
    "    \n",
    "    labels = inp[\"labels\"].to(config.DEVICE)\n",
    "    \n",
    "    preds = model.decode_predictions(\n",
    "            predicted_ids=pred_ids\n",
    "    )[0]\n",
    "\n",
    "    label = model.decode_predictions(\n",
    "        predicted_ids=labels\n",
    "    )[0]  \n",
    "    \n",
    "    # compute metrics\n",
    "    val_loss = loss_fn(logits.view(-1, logits.shape[2]), labels.view(-1)).item()  # loss\n",
    "    cer = model.cer_fn(preds, label).item() # Character Error Rate\n",
    "    wer = model.wer_fn(preds, label).item() # Word Error Rate\n",
    "    \n",
    "    output = {\n",
    "        \"val_loss\"              : val_loss,\n",
    "        \"CER\"                   : cer,\n",
    "        \"WER\"                   : wer,\n",
    "        \"label\"                 : label,\n",
    "        \"pred_ids\"              : pred_ids,\n",
    "        \"pred_tokens\"           : preds,\n",
    "        \"self_attn_ws\"          : self_attn_ws, \n",
    "        \"cross_attn_ws\"         : cross_attn_ws\n",
    "    }\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acdc48d0-39f7-4f62-8172-79e138d07ca1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 235 ms, sys: 8.05 ms, total: 243 ms\n",
      "Wall time: 779 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 7.094069480895996,\n",
       " 'CER': 0.8500000238418579,\n",
       " 'WER': 1.0,\n",
       " 'label': \":BOWL GREEN POSE-10 :BOWL #'*rightward-transformation* :BOWL\",\n",
       " 'pred_ids': tensor([[32, 11,  5, 32,  2, 32,  2, 32,  2, 32,  2, 32,  2, 32,  2, 32]]),\n",
       " 'pred_tokens': 'POSE-11 :CEREAL :SPOON POSE-11',\n",
       " 'self_attn_ws': tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.2027e-02, 9.7797e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.7161e-01, 8.8347e-02, 5.4005e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [3.8384e-02, 4.2258e-02, 3.1755e-04,  ..., 1.6146e-02,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.1579e-03, 1.3016e-01, 3.4435e-03,  ..., 3.1899e-02,\n",
       "            9.4373e-02, 0.0000e+00],\n",
       "           [1.7627e-02, 4.2222e-02, 5.8494e-04,  ..., 1.0933e-02,\n",
       "            1.6845e-02, 9.8074e-03]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [8.5624e-01, 1.4376e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [8.7642e-01, 1.0802e-01, 1.5556e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [7.6685e-02, 1.5863e-01, 1.0456e-01,  ..., 1.8089e-03,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.8260e-01, 1.7900e-02, 1.3719e-01,  ..., 1.3244e-02,\n",
       "            1.4627e-02, 0.0000e+00],\n",
       "           [9.7006e-02, 1.3322e-01, 1.1997e-01,  ..., 2.1423e-03,\n",
       "            9.7860e-02, 3.9966e-03]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.4328e-01, 4.5672e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [4.9648e-03, 9.8570e-01, 9.3366e-03,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [3.6502e-02, 6.7256e-02, 7.6258e-02,  ..., 8.8088e-02,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.6874e-01, 1.9267e-02, 3.4016e-02,  ..., 1.0310e-01,\n",
       "            7.5888e-03, 0.0000e+00],\n",
       "           [2.8104e-02, 4.1424e-02, 4.3619e-02,  ..., 7.7437e-02,\n",
       "            9.1409e-02, 9.4356e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.5359e-01, 6.4641e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [9.9410e-03, 9.7020e-01, 1.9860e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [2.6110e-01, 1.6436e-01, 9.9901e-02,  ..., 2.0852e-02,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [4.8121e-02, 1.6899e-01, 1.0980e-01,  ..., 1.3613e-03,\n",
       "            8.0316e-02, 0.0000e+00],\n",
       "           [2.1973e-01, 1.3015e-01, 1.2517e-01,  ..., 1.6707e-02,\n",
       "            1.8595e-02, 1.6897e-02]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [9.9433e-01, 5.6712e-03, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [7.4952e-02, 3.4521e-01, 5.7984e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [5.3689e-03, 4.5120e-04, 8.3369e-02,  ..., 1.5881e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.7768e-01, 4.6532e-03, 1.9474e-01,  ..., 3.6077e-02,\n",
       "            1.1820e-02, 0.0000e+00],\n",
       "           [7.2750e-03, 3.5786e-04, 5.5144e-02,  ..., 1.6387e-01,\n",
       "            1.3347e-04, 9.2997e-02]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [7.0859e-01, 2.9141e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.2797e-01, 3.4767e-01, 1.2436e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [8.7513e-03, 1.4592e-01, 7.9151e-03,  ..., 3.4980e-02,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.7572e-01, 1.2181e-01, 5.4974e-03,  ..., 3.4462e-02,\n",
       "            3.3568e-02, 0.0000e+00],\n",
       "           [9.1413e-03, 1.1814e-01, 9.4850e-03,  ..., 3.0679e-02,\n",
       "            6.7675e-02, 4.3272e-02]]]]),\n",
       " 'cross_attn_ws': tensor([[[[0.0209, 0.0208, 0.0208,  ..., 0.0211, 0.0204, 0.0209],\n",
       "           [0.0209, 0.0209, 0.0207,  ..., 0.0208, 0.0210, 0.0207],\n",
       "           [0.0209, 0.0205, 0.0208,  ..., 0.0210, 0.0206, 0.0212],\n",
       "           ...,\n",
       "           [0.0208, 0.0208, 0.0207,  ..., 0.0209, 0.0209, 0.0210],\n",
       "           [0.0209, 0.0208, 0.0207,  ..., 0.0206, 0.0212, 0.0207],\n",
       "           [0.0208, 0.0208, 0.0207,  ..., 0.0209, 0.0209, 0.0209]],\n",
       " \n",
       "          [[0.0209, 0.0203, 0.0210,  ..., 0.0207, 0.0209, 0.0213],\n",
       "           [0.0208, 0.0206, 0.0211,  ..., 0.0206, 0.0210, 0.0209],\n",
       "           [0.0209, 0.0206, 0.0208,  ..., 0.0209, 0.0207, 0.0210],\n",
       "           ...,\n",
       "           [0.0206, 0.0209, 0.0209,  ..., 0.0208, 0.0209, 0.0209],\n",
       "           [0.0208, 0.0209, 0.0209,  ..., 0.0209, 0.0208, 0.0208],\n",
       "           [0.0206, 0.0209, 0.0209,  ..., 0.0208, 0.0209, 0.0209]],\n",
       " \n",
       "          [[0.0209, 0.0206, 0.0209,  ..., 0.0207, 0.0209, 0.0208],\n",
       "           [0.0210, 0.0208, 0.0209,  ..., 0.0210, 0.0205, 0.0207],\n",
       "           [0.0209, 0.0210, 0.0209,  ..., 0.0209, 0.0206, 0.0207],\n",
       "           ...,\n",
       "           [0.0209, 0.0206, 0.0211,  ..., 0.0207, 0.0206, 0.0208],\n",
       "           [0.0209, 0.0207, 0.0209,  ..., 0.0210, 0.0205, 0.0209],\n",
       "           [0.0209, 0.0206, 0.0211,  ..., 0.0206, 0.0207, 0.0208]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0208, 0.0205, 0.0210,  ..., 0.0204, 0.0213, 0.0210],\n",
       "           [0.0209, 0.0205, 0.0211,  ..., 0.0205, 0.0211, 0.0210],\n",
       "           [0.0209, 0.0208, 0.0209,  ..., 0.0208, 0.0211, 0.0207],\n",
       "           ...,\n",
       "           [0.0208, 0.0206, 0.0211,  ..., 0.0205, 0.0211, 0.0210],\n",
       "           [0.0209, 0.0206, 0.0211,  ..., 0.0205, 0.0208, 0.0209],\n",
       "           [0.0208, 0.0205, 0.0211,  ..., 0.0204, 0.0211, 0.0210]],\n",
       " \n",
       "          [[0.0207, 0.0208, 0.0208,  ..., 0.0208, 0.0207, 0.0211],\n",
       "           [0.0208, 0.0210, 0.0209,  ..., 0.0206, 0.0209, 0.0207],\n",
       "           [0.0208, 0.0212, 0.0208,  ..., 0.0207, 0.0208, 0.0205],\n",
       "           ...,\n",
       "           [0.0210, 0.0211, 0.0207,  ..., 0.0211, 0.0205, 0.0206],\n",
       "           [0.0208, 0.0208, 0.0210,  ..., 0.0206, 0.0207, 0.0208],\n",
       "           [0.0210, 0.0211, 0.0208,  ..., 0.0211, 0.0205, 0.0207]],\n",
       " \n",
       "          [[0.0211, 0.0208, 0.0206,  ..., 0.0215, 0.0204, 0.0209],\n",
       "           [0.0211, 0.0204, 0.0210,  ..., 0.0209, 0.0207, 0.0209],\n",
       "           [0.0208, 0.0208, 0.0210,  ..., 0.0206, 0.0209, 0.0208],\n",
       "           ...,\n",
       "           [0.0207, 0.0210, 0.0208,  ..., 0.0208, 0.0210, 0.0207],\n",
       "           [0.0209, 0.0206, 0.0210,  ..., 0.0208, 0.0209, 0.0209],\n",
       "           [0.0207, 0.0210, 0.0208,  ..., 0.0208, 0.0209, 0.0206]]]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out = validation_step(model=rt1, batch=batch, loss_fn=loss_fn)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b726401-4a3a-4a8a-a1ba-4dab8d79af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSE-11 :CEREAL :SPOON POSE-11']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt1.decode_predictions(predicted_ids=out[\"pred_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8dbf5-0c21-40f9-ad2f-a7756961d03e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üßëüèæ‚Äçüç≥ Prepare Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "643f24ee-c2cc-4cd3-bb87-e898490c0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, dm, opt, loss_fn, scheduler):\n",
    "    \n",
    "    loss_epoch = np.inf\n",
    "    val_loss = np.inf\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    cer_ = np.inf\n",
    "    wer_ = np.inf\n",
    "    \n",
    "    for e in range(config.EPOCHS):        \n",
    "        running_loss = 0.\n",
    "        num_steps = len(dm.train_dataloader())\n",
    "        \n",
    "        pbar = tqdm(\n",
    "            range(num_steps),\n",
    "            position=0,\n",
    "            leave=True,\n",
    "            dynamic_ncols=True,\n",
    "            total = num_steps\n",
    "        )\n",
    "        \n",
    "        # training\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dm.train_dataloader()):            \n",
    "            pct = 100. * step / num_steps\n",
    "            pbar.set_description(\n",
    "                f\"Epoch {e+1}/{config.EPOCHS} - (Train {pct:.1f}%)\"\n",
    "            )\n",
    "            pbar.update()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "\n",
    "            # training step\n",
    "            loss, logits, self_attn_ws, cross_attn_ws = training_step(\n",
    "                model=model, \n",
    "                batch=batch, \n",
    "                loss_fn=loss_fn\n",
    "            )\n",
    "            \n",
    "            # plot attention weights\n",
    "            plot_attention(\n",
    "                self_attn_ws, \n",
    "                show=False, \n",
    "                pre_fix=\"train_selfattn\", \n",
    "                folder=\"train\",\n",
    "                epoch=e,\n",
    "                wandb_logging=True\n",
    "            )\n",
    "\n",
    "            plot_attention(\n",
    "                cross_attn_ws,\n",
    "                kind=\"cross\", \n",
    "                pre_fix=\"train_crossattn\", \n",
    "                show=False, \n",
    "                folder=\"train\",\n",
    "                epoch=e,\n",
    "                wandb_logging=True\n",
    "            )   \n",
    "            \n",
    "            running_loss += loss.item()         \n",
    "            \n",
    "            # logging\n",
    "            if step % 10 == 0:\n",
    "                pbar.set_postfix(\n",
    "                    train_loss_step=\"{:.04f}\".format(running_loss/(step+1)),\n",
    "                    train_loss=\"{:.04f}\".format(loss_epoch),\n",
    "                    CER=\"{:.04f}\".format(cer_),\n",
    "                    WER=\"{:.04f}\".format(wer_),\n",
    "                    val_loss=\"{:.04f}\".format(val_loss),\n",
    "                )\n",
    "                pbar.update()\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # Adjust learning weights\n",
    "            opt.step()\n",
    "            \n",
    "        loss_epoch = running_loss / len(dm.train_dataloader())   \n",
    "        final_lr_epoch = float(opt.param_groups[0]['lr'])\n",
    "        \n",
    "        # predictions\n",
    "        preds = logits.softmax(dim=-1).argmax(dim=-1)\n",
    "\n",
    "        # decode predictions\n",
    "        preds = model.decode_predictions(\n",
    "            predicted_ids=preds\n",
    "        )\n",
    "\n",
    "        labels = model.decode_predictions(\n",
    "            predicted_ids=batch[\"motor_cmd\"][\"labels\"]\n",
    "        )         \n",
    "            \n",
    "        # log decoded sentenses\n",
    "        with open(config.LOGGING_FILE, \"a\") as f:            \n",
    "            f.write(f\"Epoch #{e+1}\\n\")\n",
    "            f.write(f\"[Train] \\n\")\n",
    "            \n",
    "            pred = preds[0]\n",
    "            label = labels[0]\n",
    "            \n",
    "            cer_ = model.cer_fn(pred, label).item()\n",
    "            wer_ = model.wer_fn(pred, label).item()\n",
    "            f.write(f\"Predicted \\t: {pred}\\n\")\n",
    "            f.write(f\"Actual \\t\\t: {label}\\n\")\n",
    "                \n",
    "        # validation\n",
    "        out = validation_step(model=rt1, batch=batch, loss_fn=loss_fn)\n",
    "        val_loss = out[\"val_loss\"]\n",
    "        \n",
    "        # start scheduling lr after epoch X\n",
    "        # X set to 30 to start us of\n",
    "        if e >=30:\n",
    "            scheduler.step(val_loss)\n",
    "       \n",
    "        # plot attention weights\n",
    "        plot_attention(\n",
    "            out[\"self_attn_ws\"], \n",
    "            show=False, \n",
    "            pre_fix=\"val_selfattn\", \n",
    "            folder=\"val\",\n",
    "            epoch=e,\n",
    "            wandb_logging=True\n",
    "        )\n",
    "\n",
    "        plot_attention(\n",
    "            out[\"cross_attn_ws\"],\n",
    "            kind=\"cross\", \n",
    "            pre_fix=\"val_crossattn\", \n",
    "            show=False, \n",
    "            folder=\"val\",\n",
    "            epoch=e,\n",
    "            wandb_logging=True\n",
    "        )   \n",
    "        \n",
    "        # update best score\n",
    "        if val_loss < best_val_loss:\n",
    "            # save checkpoint\n",
    "            path = os.path.join(config.MODEL_PATH, \"be_model.bin\")\n",
    "            torch.save({\n",
    "                'model_state_dict'      :model.state_dict(),\n",
    "                'optimizer_state_dict'  :opt.state_dict(),\n",
    "                'val_loss'              : val_loss, \n",
    "                'epoch'                 : e\n",
    "                }, path)\n",
    "            \n",
    "            # update best score\n",
    "            best_val_loss = val_loss        \n",
    "        \n",
    "        pbar.set_postfix(\n",
    "            train_loss_step=\"{:.04f}\".format(running_loss/(step+1)),\n",
    "            train_loss=\"{:.04f}\".format(loss_epoch),\n",
    "            # CER=\"{:.04f}\".format(cer_),\n",
    "            # WER=\"{:.04f}\".format(wer_),\n",
    "            val_Loss=\"{:.04f}\".format(val_loss),\n",
    "            val_CER=\"{:.04f}\".format(out[\"CER\"]),\n",
    "            val_WER=\"{:.04f}\".format(out[\"WER\"]),\n",
    "            lr_epoch=\"{:.1e}\".format(final_lr_epoch),\n",
    "        )  \n",
    "        pbar.update()\n",
    "        \n",
    "        logs_dict = {\n",
    "            \"epoch\" :e,\n",
    "            \"train_loss\":loss_epoch,\n",
    "            \"val_loss\":val_loss,\n",
    "            \"val_CER\":out[\"CER\"],\n",
    "            \"valWER\":out[\"WER\"],\n",
    "            \"lr\":final_lr_epoch\n",
    "        }\n",
    "        wandb.log(logs_dict)\n",
    "        \n",
    "        # log decoded sentenses\n",
    "        with open(config.LOGGING_FILE, \"a\") as f:                        \n",
    "            pred = out[\"pred_tokens\"]\n",
    "            label = out[\"label\"]\n",
    "            \n",
    "            f.write(f\"[Val] \\n\")            \n",
    "            f.write(f\"Predicted \\t: {pred}\\n\")\n",
    "            f.write(f\"Actual \\t\\t: {label}\\n\") \n",
    "            f.write(f\"Curr val loss \\t\\t: {val_loss:.5f}\\n\") \n",
    "            f.write(f\"Best loss: \\t\\t: {best_val_loss:.5f}\\n\\n\") \n",
    "            \n",
    "        pbar.close()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffd0fb-8dcb-4d92-b2e9-72be3348c68d",
   "metadata": {},
   "source": [
    "## üöÄ Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b805dc-8fe1-4324-a3aa-89ad21471aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "\n",
    "random.seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(config.SEED)\n",
    "    torch.cuda.manual_seed_all(config.SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a5ef6-3a47-4c74-870d-7e10937009b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdric225\u001b[0m (\u001b[33mjepsam-s23\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ocean/projects/cis230036p/cmanouan/repo/smf_be/notebooks/wandb/run-20231216_002738-jwaaol6b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jepsam-s23/SMF-Be/runs/jwaaol6b' target=\"_blank\">be_model</a></strong> to <a href='https://wandb.ai/jepsam-s23/SMF-Be' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jepsam-s23/SMF-Be' target=\"_blank\">https://wandb.ai/jepsam-s23/SMF-Be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jepsam-s23/SMF-Be/runs/jwaaol6b' target=\"_blank\">https://wandb.ai/jepsam-s23/SMF-Be/runs/jwaaol6b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ab22eef8984ea4acd71a57e9b27e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7bcb57ad164df78ab3c98c3fe30046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715f5c3a31e040ea9b9476f213660a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac34c8d2fd8744c28a6ea17cfdca633c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### init experiment\n",
    "run = wandb.init(\n",
    "    project='SMF-Be', \n",
    "    group=\"RT1-CRAM\", \n",
    "    name=\"be_model\", \n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "with open(config.LOGGING_FILE, \"a\") as f:   \n",
    "    f.write(\"*** New experiment ***\\n\")\n",
    "    \n",
    "    \n",
    "trained_model = run_experiment(\n",
    "    model=rt1, \n",
    "    dm=dm, \n",
    "    opt=opt, \n",
    "    loss_fn=loss_fn,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa000104-cc3b-4927-ae6e-b7ec8745e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac23076-a4a3-459a-b714-eb4ad052fbb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üë®üèø‚Äçüî¨ Test / Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c8ac-54da-4758-9382-a7e0c8ec8294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9c86c-0345-4fe7-b85b-07cdb971a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids=batch[\"action_desc\"][\"ids\"].cuda()\n",
    "# attn_mask=batch[\"action_desc\"][\"mask\"].cuda()\n",
    "# token_type_ids=batch[\"action_desc\"][\"token_type_ids\"].cuda()\n",
    "# imgs=batch[\"in_state\"].cuda()\n",
    "# decoder_inp=batch[\"motor_cmd\"][\"decoder_inp_ids\"].cuda()\n",
    "# src_mask=(batch[\"source_mask\"].cuda(), batch[\"source_mask_tokens\"].cuda())\n",
    "# target_mask=batch[\"target_mask\"].cuda()\n",
    "# labels = batch[\"motor_cmd\"][\"labels\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2c917-08ae-444c-a456-fd3ace430e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed396280-b161-4b1f-b8b6-0801e3786cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0a9f9-42d6-4905-bc84-c23b468c7c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246745c7-2958-493c-90b9-94e77b0b85b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMF-BE",
   "language": "python",
   "name": "smf-be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
