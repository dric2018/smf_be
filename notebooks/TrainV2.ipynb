{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51054b27-9fd9-4a34-9c80-9519b2fb3060",
   "metadata": {},
   "source": [
    "## ü§î Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d77a40d-8e01-420e-b572-fe22bd600f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 04:39:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    40W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f74170-ded5-4ca1-81b1-7b3857810090",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üõ†Ô∏è Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ff9e3c-a68b-4a84-ab94-c2cd07294dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0920d519-4636-47e0-977c-c0d6583ba014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import RichProgressBar, TQDMProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "import math\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import time\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ae7b8b-5631-4c2b-a735-43e3cee5cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec61ddc-e278-454c-b6ec-538359e04c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from dataloader import BEDataset, BEDataModule\n",
    "from transformer import generate_causal_attention_mask\n",
    "\n",
    "from rt1 import RT1CRAM\n",
    "from utils.model_utils import plot_attention, fetch_sample_from_batch\n",
    "import utils.data_utils as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79af0e-70f8-4b36-b69a-b25466aa88b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìä Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df6190a-d007-4387-b470-f7ea1063f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on 4049 samples.\n",
      "INFO:root:Validating on 459 samples.\n",
      "INFO:root:Testing on 250 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # examples: 4758\n"
     ]
    }
   ],
   "source": [
    "dm = BEDataModule()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c0210-17c3-4054-af37-3658ddc4799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sample_id', 'in_state', 'action_desc', 'source_mask_tokens', 'source_mask', 'motor_cmd', 'target_mask'])\n",
      "CPU times: user 1.64 s, sys: 2.11 s, total: 3.75 s\n",
      "Wall time: 32.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 288, 288])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(batch.keys())\n",
    "batch[\"in_state\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ff744-12e8-4052-9d4b-df1c92b76390",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ü§ñ RT1-CRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f735344-d5e5-4193-a4f8-bde3804622fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b3.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b3.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "RT1CRAM                                                           --\n",
       "‚îú‚îÄRT1Encoder: 1-1                                                 --\n",
       "‚îÇ    ‚îî‚îÄTextEncoder: 2-1                                           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBertModel: 3-1                                        (28,763,648)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-2                                          --\n",
       "‚îÇ    ‚îî‚îÄFiLMEncoder: 2-2                                           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄImageFeatureExtractor: 3-3                            10,300,456\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4                                       3,170,304\n",
       "‚îÇ    ‚îî‚îÄTokenLearnerV11: 2-3                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-5                                       134,408\n",
       "‚îú‚îÄRT1Decoder: 1-2                                                 --\n",
       "‚îÇ    ‚îî‚îÄEmbedding: 2-4                                             26,624\n",
       "‚îÇ    ‚îî‚îÄTransformerDecoder: 2-5                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-6                                           262,656\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-7                                           8,704\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-8                                       26,219,008\n",
       "‚îÇ    ‚îî‚îÄLayerNormalization: 2-6                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-9                                        1,024\n",
       "‚îÇ    ‚îî‚îÄActionGenerator: 2-7                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-10                                      26,676\n",
       "‚îú‚îÄCrossEntropyLoss: 1-3                                           --\n",
       "‚îú‚îÄCharErrorRate: 1-4                                              --\n",
       "‚îú‚îÄWordErrorRate: 1-5                                              --\n",
       "==========================================================================================\n",
       "Total params: 68,913,508\n",
       "Trainable params: 30,046,524\n",
       "Non-trainable params: 38,866,984\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt1 = RT1CRAM(\n",
    "    cnn_bacnbone=config.SELECTED_CNN_BACKBONE, \n",
    "    num_res_blocks=config.NUM_RES_BLOCKS,\n",
    "    freeze_cnn_backbone=config.FREEZE_CNN\n",
    ").cuda()\n",
    "# print(rt1)\n",
    "\n",
    "summary(model=rt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe02812-d0e2-4a8a-b562-af007ef094be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üèãÔ∏è‚Äç Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9d22df-8a7b-4cba-8811-dd0bd796815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0003\n",
       "    maximize: False\n",
       "    weight_decay: 2e-06\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    ignore_index=config.TGT_PAD_TOK_ID, \n",
    "    label_smoothing=config.LABEL_SMOOTHING\n",
    ")\n",
    "\n",
    "opt = getattr(torch.optim, config.OPTIMIZER)(\n",
    "    params=[p for p in rt1.parameters() if p.requires_grad], \n",
    "    lr=config.LR,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = getattr(torch.optim.lr_scheduler, config.LR_SCHEDULER[\"type\"])(**config.LR_SCHEDULER[\"params\"], optimizer=opt)\n",
    "\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989aec1b-f692-4e0b-99ab-9fc7c97a38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch, loss_fn):\n",
    "\n",
    "    input_ids=batch[\"action_desc\"][\"ids\"].to(config.DEVICE)\n",
    "    attn_mask=batch[\"action_desc\"][\"mask\"].to(config.DEVICE)\n",
    "    token_type_ids=batch[\"action_desc\"][\"token_type_ids\"].to(config.DEVICE)\n",
    "    imgs=batch[\"in_state\"].to(config.DEVICE)\n",
    "    decoder_inp=batch[\"motor_cmd\"][\"decoder_inp_ids\"].to(config.DEVICE)\n",
    "    src_mask=(batch[\"source_mask\"].to(config.DEVICE), batch[\"source_mask_tokens\"].to(config.DEVICE))\n",
    "    target_mask=batch[\"target_mask\"].to(config.DEVICE)\n",
    "    \n",
    "    # forward\n",
    "    logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens = model(\n",
    "        input_ids=input_ids, \n",
    "        attn_mask=attn_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        imgs=imgs,\n",
    "        decoder_inp=decoder_inp, \n",
    "        src_mask=src_mask, \n",
    "        target_mask=target_mask \n",
    "    )\n",
    "\n",
    "    # loss computation\n",
    "    labels = batch[\"motor_cmd\"][\"labels\"].to(config.DEVICE)\n",
    "    loss = loss_fn(logits.view(-1, logits.shape[2]), labels.view(-1))\n",
    "        \n",
    "    return loss, logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4bbf71-5c90-44de-abaf-679aeb45b0fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üõü Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ce1de8-a9ca-494a-ad5a-5e10b26eda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(\n",
    "    model:pl.LightningModule, \n",
    "    batch_inp:dict, \n",
    "    max_len:int=config.MAX_OUT_SEQ_LEN, \n",
    "    debug:bool=False\n",
    "):\n",
    "    if model.device.type == \"cpu\":\n",
    "        model.to(config.DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    sos_token = config.TARGETS_MAPPING[\"[SOS]\"]\n",
    "    eos_token = config.TARGETS_MAPPING[\"[EOS]\"]\n",
    "    \n",
    "    input_ids=batch_inp[\"ids\"].to(config.DEVICE)\n",
    "    attn_mask=batch_inp[\"mask\"].to(config.DEVICE)\n",
    "    token_type_ids=batch_inp[\"token_type_ids\"].to(config.DEVICE)\n",
    "    imgs=batch_inp[\"in_state\"].to(config.DEVICE)\n",
    "    src_mask=(\n",
    "        batch_inp[\"source_mask\"].to(config.DEVICE), \n",
    "        batch_inp[\"source_mask_tokens\"].to(config.DEVICE)\n",
    "    )\n",
    "\n",
    "    text_enc_last_h, learned_tokens = model._encode(\n",
    "        input_ids=input_ids, \n",
    "        attn_mask=attn_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        imgs=imgs    \n",
    "    )\n",
    "    \n",
    "    decoder_inp = torch.empty(1, 1, dtype=torch.long, device=input_ids.device).fill_(sos_token)\n",
    "\n",
    "    # decoding procedure\n",
    "    for t in range(max_len):\n",
    "        \n",
    "        decoder_mask = generate_causal_attention_mask(\n",
    "            dim=decoder_inp.shape[1]\n",
    "        ).type_as(attn_mask)\n",
    "        \n",
    "        # generate predictions\n",
    "        with torch.no_grad():\n",
    "            logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens = model._decode(\n",
    "            decoder_inp=decoder_inp, \n",
    "            encoder_outs=(text_enc_last_h, learned_tokens), \n",
    "            src_mask=src_mask, \n",
    "            target_mask=decoder_mask,\n",
    "            debug=debug,\n",
    "            return_actions=False\n",
    "        )\n",
    "\n",
    "        # perform greedy decoding\n",
    "        probs = model.decoder.action_generator(logits[:, -1])\n",
    "            \n",
    "        _, next_tok = torch.max(probs, dim=-1)\n",
    "        # update decoder input\n",
    "        decoder_inp = torch.cat((decoder_inp, next_tok.unsqueeze(1)), dim=1)\n",
    "            \n",
    "    return decoder_inp[:, 1:].cpu().detach(), logits, self_attn_ws.cpu().detach(), cross_attn_ws_seq.cpu().detach(), cross_attn_ws_tokens.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff9aedb-5a52-48f6-b8df-d2cff2439aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(batch, model, loss_fn, debug:bool=False):\n",
    "    inp = fetch_sample_from_batch(\n",
    "        batch, \n",
    "        batch_size=batch[\"in_state\"].shape[0],\n",
    "        random=True\n",
    "    )\n",
    "    \n",
    "    pred_ids, logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens = greedy_decoding(\n",
    "        model=model, \n",
    "        batch_inp=inp, \n",
    "        debug=debug\n",
    "    )\n",
    "    \n",
    "    labels = inp[\"labels\"].to(config.DEVICE)\n",
    "    \n",
    "    preds = model.decode_predictions(\n",
    "            predicted_ids=pred_ids\n",
    "    )[0]\n",
    "\n",
    "    label = model.decode_predictions(\n",
    "        predicted_ids=labels\n",
    "    )[0]  \n",
    "    \n",
    "    # compute metrics\n",
    "    val_loss = loss_fn(logits.view(-1, logits.shape[2]), labels.view(-1)).item()  # loss\n",
    "    cer = model.cer_fn(preds, label).item() # Character Error Rate\n",
    "    wer = model.wer_fn(preds, label).item() # Word Error Rate\n",
    "    \n",
    "    output = {\n",
    "        \"val_loss\"              : val_loss,\n",
    "        \"CER\"                   : cer,\n",
    "        \"WER\"                   : wer,\n",
    "        \"label\"                 : label,\n",
    "        \"pred_ids\"              : pred_ids,\n",
    "        \"pred_tokens\"           : preds,\n",
    "        \"self_attn_ws\"          : self_attn_ws, \n",
    "        \"cross_attn_ws_seq\"     : cross_attn_ws_seq, \n",
    "        \"cross_attn_ws_tokens\"  : cross_attn_ws_tokens\n",
    "    }\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2be6db-be4c-415f-a56b-9158229cbe91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 6.728468418121338,\n",
       " 'CER': 1.0,\n",
       " 'WER': 1.7777777910232544,\n",
       " 'label': \":MILK RED POSE-8 :CAP RED POSE-1 :MILK #'*leftward-transformation* :CAP\",\n",
       " 'pred_ids': tensor([[40, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46]]),\n",
       " 'pred_tokens': 'POSE-2 BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE BLUE',\n",
       " 'self_attn_ws': tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 5.8140e-16,  ..., 0.0000e+00,\n",
       "            2.0092e-37, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 4.3933e-23,  ..., 1.8333e-12,\n",
       "            3.6262e-28, 1.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 2.9587e-21,  ..., 1.3839e-11,\n",
       "            4.5463e-30, 1.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 4.1969e-22,  ..., 4.4405e-12,\n",
       "            1.2085e-30, 1.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.2594e-21,  ..., 1.4109e-13,\n",
       "            3.9368e-27, 1.0000e+00]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.2789e-17,  ..., 2.5044e-24,\n",
       "            2.5718e-38, 1.3312e-43],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00, 1.1613e-12,  ..., 5.9841e-09,\n",
       "            1.6290e-22, 1.0824e-13],\n",
       "           [0.0000e+00, 0.0000e+00, 1.6747e-28,  ..., 6.2623e-33,\n",
       "            5.7836e-26, 4.7401e-26],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 4.6373e-29,  ..., 2.6513e-33,\n",
       "            2.3195e-25, 5.2284e-25],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0400e-26,  ..., 1.7467e-30,\n",
       "            2.2506e-24, 2.3159e-24],\n",
       "           [0.0000e+00, 0.0000e+00, 2.0608e-28,  ..., 1.3951e-33,\n",
       "            2.4063e-25, 2.1062e-26]],\n",
       " \n",
       "          [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.2181e-01, 0.0000e+00, 2.1413e-11,  ..., 8.0460e-05,\n",
       "            7.6848e-04, 1.2518e-12],\n",
       "           ...,\n",
       "           [2.0081e-20, 0.0000e+00, 1.0998e-09,  ..., 1.1547e-03,\n",
       "            1.7731e-02, 5.6136e-14],\n",
       "           [1.0000e+00, 0.0000e+00, 4.0268e-28,  ..., 3.4283e-20,\n",
       "            8.6688e-20, 4.4410e-28],\n",
       "           [1.6469e-16, 0.0000e+00, 1.9562e-10,  ..., 1.0691e-05,\n",
       "            1.9460e-03, 9.5523e-14]]]]),\n",
       " 'cross_attn_ws_seq': tensor([[[[0.0466, 0.0418, 0.0804,  ..., 0.0631, 0.0661, 0.0592],\n",
       "           [0.0946, 0.0374, 0.0448,  ..., 0.0744, 0.0987, 0.0793],\n",
       "           [0.0693, 0.0522, 0.0640,  ..., 0.1113, 0.0734, 0.0610],\n",
       "           ...,\n",
       "           [0.0647, 0.0507, 0.0676,  ..., 0.1120, 0.0730, 0.0627],\n",
       "           [0.0788, 0.0548, 0.0608,  ..., 0.1112, 0.0774, 0.0596],\n",
       "           [0.0669, 0.0507, 0.0643,  ..., 0.1102, 0.0731, 0.0638]],\n",
       " \n",
       "          [[0.1358, 0.0805, 0.0195,  ..., 0.0519, 0.0518, 0.0605],\n",
       "           [0.0789, 0.0925, 0.0557,  ..., 0.0464, 0.0305, 0.0393],\n",
       "           [0.0822, 0.1254, 0.0664,  ..., 0.0645, 0.0601, 0.0773],\n",
       "           ...,\n",
       "           [0.0816, 0.1250, 0.0717,  ..., 0.0648, 0.0594, 0.0775],\n",
       "           [0.0791, 0.1106, 0.0555,  ..., 0.0671, 0.0643, 0.0798],\n",
       "           [0.0825, 0.1278, 0.0719,  ..., 0.0647, 0.0594, 0.0764]],\n",
       " \n",
       "          [[0.1137, 0.1358, 0.0543,  ..., 0.0557, 0.0526, 0.0479],\n",
       "           [0.1306, 0.0921, 0.0340,  ..., 0.0369, 0.0452, 0.0319],\n",
       "           [0.0858, 0.0389, 0.0177,  ..., 0.0634, 0.0928, 0.0815],\n",
       "           ...,\n",
       "           [0.0816, 0.0402, 0.0187,  ..., 0.0650, 0.0928, 0.0808],\n",
       "           [0.0911, 0.0384, 0.0178,  ..., 0.0638, 0.0911, 0.0826],\n",
       "           [0.0827, 0.0402, 0.0188,  ..., 0.0635, 0.0924, 0.0812]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0467, 0.0270, 0.0612,  ..., 0.0562, 0.0466, 0.0715],\n",
       "           [0.0803, 0.0285, 0.0229,  ..., 0.0551, 0.0550, 0.0607],\n",
       "           [0.0358, 0.0537, 0.0731,  ..., 0.0904, 0.0654, 0.0869],\n",
       "           ...,\n",
       "           [0.0370, 0.0520, 0.0751,  ..., 0.0944, 0.0650, 0.0871],\n",
       "           [0.0336, 0.0568, 0.0649,  ..., 0.0804, 0.0673, 0.0873],\n",
       "           [0.0370, 0.0529, 0.0784,  ..., 0.0939, 0.0644, 0.0866]],\n",
       " \n",
       "          [[0.0553, 0.0674, 0.0628,  ..., 0.0648, 0.0571, 0.0542],\n",
       "           [0.0476, 0.0501, 0.1044,  ..., 0.0445, 0.0447, 0.0430],\n",
       "           [0.0630, 0.0638, 0.0437,  ..., 0.0622, 0.0943, 0.0721],\n",
       "           ...,\n",
       "           [0.0596, 0.0662, 0.0434,  ..., 0.0650, 0.0930, 0.0762],\n",
       "           [0.0708, 0.0573, 0.0489,  ..., 0.0582, 0.0969, 0.0642],\n",
       "           [0.0593, 0.0679, 0.0405,  ..., 0.0634, 0.0932, 0.0760]],\n",
       " \n",
       "          [[0.0549, 0.0423, 0.0365,  ..., 0.0402, 0.0481, 0.0910],\n",
       "           [0.0634, 0.0850, 0.0567,  ..., 0.0427, 0.0545, 0.0453],\n",
       "           [0.0440, 0.0471, 0.0575,  ..., 0.0624, 0.0750, 0.0828],\n",
       "           ...,\n",
       "           [0.0423, 0.0439, 0.0673,  ..., 0.0566, 0.0719, 0.0799],\n",
       "           [0.0463, 0.0547, 0.0465,  ..., 0.0754, 0.0766, 0.0825],\n",
       "           [0.0429, 0.0433, 0.0670,  ..., 0.0564, 0.0729, 0.0804]]]]),\n",
       " 'cross_attn_ws_tokens': tensor([[[[0.0211, 0.0208, 0.0204,  ..., 0.0204, 0.0207, 0.0209],\n",
       "           [0.0210, 0.0208, 0.0209,  ..., 0.0210, 0.0205, 0.0208],\n",
       "           [0.0211, 0.0209, 0.0206,  ..., 0.0206, 0.0207, 0.0210],\n",
       "           ...,\n",
       "           [0.0211, 0.0209, 0.0206,  ..., 0.0207, 0.0207, 0.0210],\n",
       "           [0.0211, 0.0209, 0.0206,  ..., 0.0206, 0.0208, 0.0209],\n",
       "           [0.0211, 0.0209, 0.0206,  ..., 0.0207, 0.0207, 0.0210]],\n",
       " \n",
       "          [[0.0204, 0.0210, 0.0213,  ..., 0.0203, 0.0205, 0.0202],\n",
       "           [0.0204, 0.0208, 0.0208,  ..., 0.0206, 0.0208, 0.0208],\n",
       "           [0.0209, 0.0208, 0.0209,  ..., 0.0207, 0.0206, 0.0206],\n",
       "           ...,\n",
       "           [0.0209, 0.0208, 0.0209,  ..., 0.0206, 0.0207, 0.0206],\n",
       "           [0.0209, 0.0208, 0.0209,  ..., 0.0207, 0.0206, 0.0206],\n",
       "           [0.0209, 0.0208, 0.0209,  ..., 0.0206, 0.0207, 0.0206]],\n",
       " \n",
       "          [[0.0205, 0.0206, 0.0206,  ..., 0.0209, 0.0209, 0.0208],\n",
       "           [0.0206, 0.0207, 0.0212,  ..., 0.0213, 0.0212, 0.0207],\n",
       "           [0.0209, 0.0207, 0.0206,  ..., 0.0211, 0.0209, 0.0211],\n",
       "           ...,\n",
       "           [0.0209, 0.0207, 0.0206,  ..., 0.0210, 0.0209, 0.0211],\n",
       "           [0.0208, 0.0208, 0.0206,  ..., 0.0212, 0.0209, 0.0212],\n",
       "           [0.0209, 0.0207, 0.0206,  ..., 0.0210, 0.0209, 0.0211]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0208, 0.0208, 0.0206,  ..., 0.0208, 0.0209, 0.0209],\n",
       "           [0.0204, 0.0207, 0.0209,  ..., 0.0215, 0.0210, 0.0212],\n",
       "           [0.0205, 0.0208, 0.0211,  ..., 0.0213, 0.0211, 0.0208],\n",
       "           ...,\n",
       "           [0.0206, 0.0208, 0.0211,  ..., 0.0213, 0.0211, 0.0208],\n",
       "           [0.0204, 0.0208, 0.0210,  ..., 0.0213, 0.0212, 0.0209],\n",
       "           [0.0206, 0.0208, 0.0211,  ..., 0.0213, 0.0211, 0.0207]],\n",
       " \n",
       "          [[0.0208, 0.0207, 0.0206,  ..., 0.0206, 0.0211, 0.0210],\n",
       "           [0.0208, 0.0208, 0.0206,  ..., 0.0207, 0.0205, 0.0209],\n",
       "           [0.0210, 0.0209, 0.0210,  ..., 0.0205, 0.0210, 0.0206],\n",
       "           ...,\n",
       "           [0.0210, 0.0209, 0.0210,  ..., 0.0205, 0.0210, 0.0206],\n",
       "           [0.0209, 0.0209, 0.0210,  ..., 0.0206, 0.0210, 0.0206],\n",
       "           [0.0210, 0.0209, 0.0210,  ..., 0.0205, 0.0210, 0.0206]],\n",
       " \n",
       "          [[0.0206, 0.0207, 0.0211,  ..., 0.0211, 0.0212, 0.0208],\n",
       "           [0.0207, 0.0207, 0.0205,  ..., 0.0209, 0.0209, 0.0212],\n",
       "           [0.0205, 0.0205, 0.0209,  ..., 0.0217, 0.0211, 0.0210],\n",
       "           ...,\n",
       "           [0.0206, 0.0205, 0.0209,  ..., 0.0218, 0.0210, 0.0210],\n",
       "           [0.0205, 0.0205, 0.0208,  ..., 0.0216, 0.0211, 0.0211],\n",
       "           [0.0206, 0.0205, 0.0209,  ..., 0.0218, 0.0210, 0.0210]]]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = validation_step(model=rt1, batch=batch, loss_fn=loss_fn)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8dbf5-0c21-40f9-ad2f-a7756961d03e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üßëüèæ‚Äçüç≥ Prepare Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643f24ee-c2cc-4cd3-bb87-e898490c0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, dm, opt, loss_fn, scheduler):\n",
    "    \n",
    "    loss_epoch = np.inf\n",
    "    val_loss = np.inf\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    cer_ = np.inf\n",
    "    wer_ = np.inf\n",
    "    \n",
    "    for e in range(config.EPOCHS):        \n",
    "        running_loss = 0.\n",
    "        num_steps = len(dm.train_dataloader())\n",
    "        \n",
    "        pbar = tqdm(\n",
    "            range(num_steps),\n",
    "            position=0,\n",
    "            leave=True,\n",
    "            dynamic_ncols=True,\n",
    "            total = num_steps\n",
    "        )\n",
    "        \n",
    "        # training\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dm.train_dataloader()):            \n",
    "            pct = 100. * step / num_steps\n",
    "            pbar.set_description(\n",
    "                f\"Epoch {e+1}/{config.EPOCHS} - (Train {pct:.1f}%)\"\n",
    "            )\n",
    "            pbar.update()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "\n",
    "            # training step\n",
    "            loss, logits, self_attn_ws, cross_attn_ws_seq, _ = training_step(\n",
    "                model=model, \n",
    "                batch=batch, \n",
    "                loss_fn=loss_fn\n",
    "            )\n",
    "            \n",
    "            # plot attention weights\n",
    "            plot_attention(\n",
    "                self_attn_ws, \n",
    "                show=False, \n",
    "                pre_fix=\"train_selfattn\", \n",
    "                folder=\"train\",\n",
    "                epoch=e,\n",
    "                wandb_logging=True\n",
    "            )\n",
    "\n",
    "            plot_attention(\n",
    "                cross_attn_ws_seq,\n",
    "                kind=\"cross\", \n",
    "                pre_fix=\"train_crossattn\", \n",
    "                show=False, \n",
    "                folder=\"train\",\n",
    "                epoch=e,\n",
    "                wandb_logging=True\n",
    "            )   \n",
    "            \n",
    "            running_loss += loss.item()         \n",
    "            \n",
    "            # logging\n",
    "            if step % 10 == 0:\n",
    "                pbar.set_postfix(\n",
    "                    train_loss_step=\"{:.04f}\".format(running_loss/(step+1)),\n",
    "                    train_loss=\"{:.04f}\".format(loss_epoch),\n",
    "                    CER=\"{:.04f}\".format(cer_),\n",
    "                    WER=\"{:.04f}\".format(wer_),\n",
    "                    val_loss=\"{:.04f}\".format(val_loss),\n",
    "                )\n",
    "                pbar.update()\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # Adjust learning weights\n",
    "            opt.step()\n",
    "            \n",
    "        loss_epoch = running_loss / len(dm.train_dataloader())   \n",
    "        final_lr_epoch = float(opt.param_groups[0]['lr'])\n",
    "        \n",
    "        # predictions\n",
    "        preds = logits.softmax(dim=-1).argmax(dim=-1)\n",
    "\n",
    "        # decode predictions\n",
    "        preds = model.decode_predictions(\n",
    "            predicted_ids=preds\n",
    "        )\n",
    "\n",
    "        labels = model.decode_predictions(\n",
    "            predicted_ids=batch[\"motor_cmd\"][\"labels\"]\n",
    "        )         \n",
    "            \n",
    "        # log decoded sentenses\n",
    "        with open(config.LOGGING_FILE, \"a\") as f:            \n",
    "            f.write(f\"Epoch #{e+1}\\n\")\n",
    "            f.write(f\"[Train] \\n\")\n",
    "            \n",
    "            pred = preds[0]\n",
    "            label = labels[0]\n",
    "            \n",
    "            cer_ = model.cer_fn(pred, label).item()\n",
    "            wer_ = model.wer_fn(pred, label).item()\n",
    "            f.write(f\"Predicted \\t: {pred}\\n\")\n",
    "            f.write(f\"Actual \\t\\t: {label}\\n\")\n",
    "                \n",
    "        # validation\n",
    "        out = validation_step(model=rt1, batch=batch, loss_fn=loss_fn)\n",
    "        val_loss = out[\"val_loss\"]\n",
    "        \n",
    "        # start scheduling lr after epoch X\n",
    "        # X set to 30 to start us of\n",
    "        if e >=30:\n",
    "            scheduler.step(val_loss)\n",
    "       \n",
    "        # plot attention weights\n",
    "        plot_attention(\n",
    "            out[\"self_attn_ws\"], \n",
    "            show=False, \n",
    "            pre_fix=\"val_selfattn\", \n",
    "            folder=\"val\",\n",
    "            epoch=e,\n",
    "            wandb_logging=True\n",
    "        )\n",
    "\n",
    "        plot_attention(\n",
    "            out[\"cross_attn_ws_seq\"],\n",
    "            kind=\"cross\", \n",
    "            pre_fix=\"val_crossattn\", \n",
    "            show=False, \n",
    "            folder=\"val\",\n",
    "            epoch=e,\n",
    "            wandb_logging=True\n",
    "        )   \n",
    "\n",
    "        # plot_attention(\n",
    "        #     out[\"cross_attn_ws_tokens\"], \n",
    "        #     pre_fix=\"val_crossattn_tokens\", \n",
    "        #     show=False, \n",
    "        #     folder=\"val\",\n",
    "        #     epoch=e,\n",
    "        #     wandb_logging=True\n",
    "        # )   \n",
    "        \n",
    "        # update best score\n",
    "        if val_loss < best_val_loss:\n",
    "            # save checkpoint\n",
    "            path = os.path.join(config.MODEL_PATH, \"be_model.bin\")\n",
    "            torch.save({\n",
    "                'model_state_dict'      :model.state_dict(),\n",
    "                'optimizer_state_dict'  :opt.state_dict(),\n",
    "                'val_loss'              : val_loss, \n",
    "                'epoch'                 : e\n",
    "                }, path)\n",
    "            \n",
    "            # update best score\n",
    "            best_val_loss = val_loss        \n",
    "        \n",
    "        pbar.set_postfix(\n",
    "            train_loss_step=\"{:.04f}\".format(running_loss/(step+1)),\n",
    "            train_loss=\"{:.04f}\".format(loss_epoch),\n",
    "            # CER=\"{:.04f}\".format(cer_),\n",
    "            # WER=\"{:.04f}\".format(wer_),\n",
    "            val_Loss=\"{:.04f}\".format(val_loss),\n",
    "            val_CER=\"{:.04f}\".format(out[\"CER\"]),\n",
    "            val_WER=\"{:.04f}\".format(out[\"WER\"]),\n",
    "            lr_epoch=\"{:.1e}\".format(final_lr_epoch),\n",
    "        )  \n",
    "        pbar.update()\n",
    "        \n",
    "        logs_dict = {\n",
    "            \"epoch\" :e,\n",
    "            \"train_loss\":loss_epoch,\n",
    "            \"val_loss\":val_loss,\n",
    "            \"val_CER\":out[\"CER\"],\n",
    "            \"valWER\":out[\"WER\"],\n",
    "            \"lr\":final_lr_epoch\n",
    "        }\n",
    "        wandb.log(logs_dict)\n",
    "        \n",
    "        # log decoded sentenses\n",
    "        with open(config.LOGGING_FILE, \"a\") as f:                        \n",
    "            pred = out[\"pred_tokens\"]\n",
    "            label = out[\"label\"]\n",
    "            \n",
    "            f.write(f\"[Val] \\n\")            \n",
    "            f.write(f\"Predicted \\t: {pred}\\n\")\n",
    "            f.write(f\"Actual \\t\\t: {label}\\n\") \n",
    "            f.write(f\"Curr val loss \\t\\t: {val_loss:.5f}\\n\") \n",
    "            f.write(f\"Best loss: \\t\\t: {best_val_loss:.5f}\\n\\n\") \n",
    "            \n",
    "        pbar.close()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffd0fb-8dcb-4d92-b2e9-72be3348c68d",
   "metadata": {},
   "source": [
    "## üöÄ Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b805dc-8fe1-4324-a3aa-89ad21471aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "\n",
    "random.seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(config.SEED)\n",
    "    torch.cuda.manual_seed_all(config.SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a5ef6-3a47-4c74-870d-7e10937009b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdric225\u001b[0m (\u001b[33mjepsam-s23\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ocean/projects/cis230036p/cmanouan/repo/smf_be/notebooks/wandb/run-20231122_044328-sj1l9p38</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jepsam-s23/SMF-Be/runs/sj1l9p38' target=\"_blank\">be_model</a></strong> to <a href='https://wandb.ai/jepsam-s23/SMF-Be' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jepsam-s23/SMF-Be' target=\"_blank\">https://wandb.ai/jepsam-s23/SMF-Be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jepsam-s23/SMF-Be/runs/sj1l9p38' target=\"_blank\">https://wandb.ai/jepsam-s23/SMF-Be/runs/sj1l9p38</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794b27233315426c8b6e1e63944d094d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83241b279e94c2da7e54bc92d3c8207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e5817854204281a783528c89365deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8669e999d44bcb9ad6849dc0be21b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056601297f604107a077d09a60ab4e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140dd0a232dc457c9bc661b42ae5e09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720d90342ecf49eea96e87dcffad1e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f035add451ae4ebeace60db00e592791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### init experiment\n",
    "run = wandb.init(\n",
    "    project='SMF-Be', \n",
    "    group=\"RT1-CRAM\", \n",
    "    name=\"be_model\", \n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "with open(config.LOGGING_FILE, \"a\") as f:   \n",
    "    f.write(\"*** New experiment ***\\n\")\n",
    "    \n",
    "    \n",
    "trained_model = run_experiment(\n",
    "    model=rt1, \n",
    "    dm=dm, \n",
    "    opt=opt, \n",
    "    loss_fn=loss_fn,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa000104-cc3b-4927-ae6e-b7ec8745e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac23076-a4a3-459a-b714-eb4ad052fbb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üë®üèø‚Äçüî¨ Test / Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c8ac-54da-4758-9382-a7e0c8ec8294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9c86c-0345-4fe7-b85b-07cdb971a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids=batch[\"action_desc\"][\"ids\"].cuda()\n",
    "# attn_mask=batch[\"action_desc\"][\"mask\"].cuda()\n",
    "# token_type_ids=batch[\"action_desc\"][\"token_type_ids\"].cuda()\n",
    "# imgs=batch[\"in_state\"].cuda()\n",
    "# decoder_inp=batch[\"motor_cmd\"][\"decoder_inp_ids\"].cuda()\n",
    "# src_mask=(batch[\"source_mask\"].cuda(), batch[\"source_mask_tokens\"].cuda())\n",
    "# target_mask=batch[\"target_mask\"].cuda()\n",
    "# labels = batch[\"motor_cmd\"][\"labels\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2c917-08ae-444c-a456-fd3ace430e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed396280-b161-4b1f-b8b6-0801e3786cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0a9f9-42d6-4905-bc84-c23b468c7c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246745c7-2958-493c-90b9-94e77b0b85b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMF-BE",
   "language": "python",
   "name": "smf-be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
