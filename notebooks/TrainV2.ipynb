{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51054b27-9fd9-4a34-9c80-9519b2fb3060",
   "metadata": {},
   "source": [
    "## ü§î Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d77a40d-8e01-420e-b572-fe22bd600f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 29 02:01:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    41W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f74170-ded5-4ca1-81b1-7b3857810090",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üõ†Ô∏è Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ff9e3c-a68b-4a84-ab94-c2cd07294dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0920d519-4636-47e0-977c-c0d6583ba014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import RichProgressBar, TQDMProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "import math\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import time\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ae7b8b-5631-4c2b-a735-43e3cee5cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec61ddc-e278-454c-b6ec-538359e04c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from dataloader import BEDataset, BEDataModule\n",
    "from transformer import generate_causal_attention_mask\n",
    "\n",
    "from rt1 import RT1CRAM\n",
    "from utils.model_utils import plot_attention, fetch_sample_from_batch\n",
    "import utils.data_utils as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79af0e-70f8-4b36-b69a-b25466aa88b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìä Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df6190a-d007-4387-b470-f7ea1063f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on 4066 samples.\n",
      "INFO:root:Validating on 442 samples.\n",
      "INFO:root:Testing on 250 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # examples: 4758\n"
     ]
    }
   ],
   "source": [
    "dm = BEDataModule()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c0210-17c3-4054-af37-3658ddc4799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sample_id', 'in_state', 'action_desc', 'source_mask_tokens', 'source_mask', 'motor_cmd', 'target_mask'])\n",
      "CPU times: user 1.03 s, sys: 587 ms, total: 1.62 s\n",
      "Wall time: 5.81 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 288, 288])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(batch.keys())\n",
    "batch[\"in_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a67f8e-a0b6-45a6-ae7d-436fbdf2a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = fetch_sample_from_batch(\n",
    "    batch, \n",
    "    batch_size=batch[\"in_state\"].shape[0],\n",
    "    random=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83167c52-6966-4526-aa0b-24dd32fb3bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sample_id', 'in_state', 'raw_action_desc', 'ids', 'mask', 'token_type_ids', 'source_mask_tokens', 'source_mask', 'raw_motor_cmd', 'decoder_inp_ids', 'labels', 'target_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1310ecd6-96ac-47af-bc49-dc2d60186624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] put the bowl in front of cereal [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_ds.tokenizer.decode(batch[\"action_desc\"][\"ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97482fdb-fe8a-4c52-9f46-2f02e8d12704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put the bowl in front of cereal'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"action_desc\"][\"raw\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ff744-12e8-4052-9d4b-df1c92b76390",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ü§ñ RT1-CRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f735344-d5e5-4193-a4f8-bde3804622fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b3.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b3.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "RT1CRAM                                                           --\n",
       "‚îú‚îÄRT1Encoder: 1-1                                                 --\n",
       "‚îÇ    ‚îî‚îÄTextEncoder: 2-1                                           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBertModel: 3-1                                        (28,763,648)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-2                                          --\n",
       "‚îÇ    ‚îî‚îÄFiLMEncoder: 2-2                                           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄImageFeatureExtractor: 3-3                            10,300,456\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4                                       4,227,072\n",
       "‚îÇ    ‚îî‚îÄTokenLearnerV11: 2-3                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-5                                       134,408\n",
       "‚îú‚îÄRT1Decoder: 1-2                                                 --\n",
       "‚îÇ    ‚îî‚îÄEmbedding: 2-4                                             26,624\n",
       "‚îÇ    ‚îî‚îÄTransformerDecoder: 2-5                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-6                                           262,656\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-7                                           8,704\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-8                                       26,219,008\n",
       "‚îÇ    ‚îî‚îÄLayerNormalization: 2-6                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-9                                        1,024\n",
       "‚îÇ    ‚îî‚îÄActionGenerator: 2-7                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-10                                      26,676\n",
       "‚îú‚îÄCrossEntropyLoss: 1-3                                           --\n",
       "‚îú‚îÄCharErrorRate: 1-4                                              --\n",
       "‚îú‚îÄWordErrorRate: 1-5                                              --\n",
       "==========================================================================================\n",
       "Total params: 69,970,276\n",
       "Trainable params: 31,103,292\n",
       "Non-trainable params: 38,866,984\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt1 = RT1CRAM(\n",
    "    cnn_bacnbone=config.SELECTED_CNN_BACKBONE, \n",
    "    num_res_blocks=config.NUM_RES_BLOCKS,\n",
    "    freeze_cnn_backbone=config.FREEZE_CNN\n",
    ").cuda()\n",
    "# print(rt1)\n",
    "\n",
    "summary(model=rt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb4411a5-870b-4c12-bed9-35ec6ef3a23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT1Encoder(\n",
       "  (text_encoder): TextEncoder(\n",
       "    (encoder): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 512)\n",
       "        (token_type_embeddings): Embedding(2, 512)\n",
       "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-3): 4 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (film_image_encoder): FiLMEncoder(\n",
       "    (feature_extractor): ImageFeatureExtractor(\n",
       "      (fe): EfficientNetFeatures(\n",
       "        (conv_stem): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): DepthwiseSeparableConv(\n",
       "              (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): DepthwiseSeparableConv(\n",
       "              (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): InvertedResidual(\n",
       "              (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): InvertedResidual(\n",
       "              (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): InvertedResidual(\n",
       "              (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): InvertedResidual(\n",
       "              (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): InvertedResidual(\n",
       "              (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): InvertedResidual(\n",
       "              (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): InvertedResidual(\n",
       "              (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): InvertedResidual(\n",
       "              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): InvertedResidual(\n",
       "              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (3): InvertedResidual(\n",
       "              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (4): InvertedResidual(\n",
       "              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): InvertedResidual(\n",
       "              (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): InvertedResidual(\n",
       "              (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): InvertedResidual(\n",
       "              (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (3): InvertedResidual(\n",
       "              (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (4): InvertedResidual(\n",
       "              (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): InvertedResidual(\n",
       "              (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): InvertedResidual(\n",
       "              (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): InvertedResidual(\n",
       "              (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (3): InvertedResidual(\n",
       "              (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (4): InvertedResidual(\n",
       "              (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (5): InvertedResidual(\n",
       "              (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): InvertedResidual(\n",
       "              (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): InvertedResidual(\n",
       "              (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNormAct2d(\n",
       "                2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "              (bn2): BatchNormAct2d(\n",
       "                2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (se): SqueezeExcite(\n",
       "                (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act1): SiLU(inplace=True)\n",
       "                (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNormAct2d(\n",
       "                384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out_layer): VisionLanguageHead(\n",
       "        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): GELU(approximate='none')\n",
       "        (global_max_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (res_blocks): ModuleList(\n",
       "      (0-3): 4 x ResBlockDWConv(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation1): GELU(approximate='none')\n",
       "        (depthwise_conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "        (pointwise_conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (film): FiLMBlockV2(\n",
       "          (projection_add): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (projection_mult): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_learner): TokenLearnerV11(\n",
       "    (token_masking): Sequential(\n",
       "      (0): LayerNormalization(\n",
       "        (layer): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt1.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4dbdd-7d92-4e58-b3c2-13b0be413d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70aa780-d2a0-4abd-a72d-4c396b026bfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m;mlm;ml\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "l;mlm;ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe02812-d0e2-4a8a-b562-af007ef094be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üèãÔ∏è‚Äç Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d22df-8a7b-4cba-8811-dd0bd796815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    ignore_index=config.TGT_PAD_TOK_ID, \n",
    "    label_smoothing=config.LABEL_SMOOTHING\n",
    ")\n",
    "\n",
    "opt = getattr(torch.optim, config.OPTIMIZER)(\n",
    "    params=[p for p in rt1.parameters() if p.requires_grad], \n",
    "    lr=config.LR,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = getattr(torch.optim.lr_scheduler, config.LR_SCHEDULER[\"type\"])(**config.LR_SCHEDULER[\"params\"], optimizer=opt)\n",
    "\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989aec1b-f692-4e0b-99ab-9fc7c97a38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch, loss_fn):\n",
    "\n",
    "    input_ids=batch[\"action_desc\"][\"ids\"].to(config.DEVICE)\n",
    "    attn_mask=batch[\"action_desc\"][\"mask\"].to(config.DEVICE)\n",
    "    token_type_ids=batch[\"action_desc\"][\"token_type_ids\"].to(config.DEVICE)\n",
    "    imgs=batch[\"in_state\"].to(config.DEVICE)\n",
    "    decoder_inp=batch[\"motor_cmd\"][\"decoder_inp_ids\"].to(config.DEVICE)\n",
    "    src_mask=(batch[\"source_mask\"].to(config.DEVICE), batch[\"source_mask_tokens\"].to(config.DEVICE))\n",
    "    target_mask=batch[\"target_mask\"].to(config.DEVICE)\n",
    "    \n",
    "    # forward\n",
    "    logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens = model(\n",
    "        input_ids=input_ids, \n",
    "        attn_mask=attn_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        imgs=imgs,\n",
    "        decoder_inp=decoder_inp, \n",
    "        src_mask=src_mask, \n",
    "        target_mask=target_mask \n",
    "    )\n",
    "\n",
    "    # loss computation\n",
    "    labels = batch[\"motor_cmd\"][\"labels\"].to(config.DEVICE)\n",
    "    loss = loss_fn(logits.view(-1, logits.shape[2]), labels.view(-1))\n",
    "        \n",
    "    return loss, logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4bbf71-5c90-44de-abaf-679aeb45b0fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üõü Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce1de8-a9ca-494a-ad5a-5e10b26eda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(\n",
    "    model:pl.LightningModule, \n",
    "    batch_inp:dict, \n",
    "    max_len:int=config.MAX_OUT_SEQ_LEN, \n",
    "    debug:bool=False\n",
    "):\n",
    "    if model.device.type == \"cpu\":\n",
    "        model.to(config.DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    sos_token = config.TARGETS_MAPPING[\"[SOS]\"]\n",
    "    eos_token = config.TARGETS_MAPPING[\"[EOS]\"]\n",
    "    \n",
    "    input_ids=batch_inp[\"ids\"].to(config.DEVICE)\n",
    "    attn_mask=batch_inp[\"mask\"].to(config.DEVICE)\n",
    "    token_type_ids=batch_inp[\"token_type_ids\"].to(config.DEVICE)\n",
    "    imgs=batch_inp[\"in_state\"].to(config.DEVICE)\n",
    "    src_mask=(\n",
    "        batch_inp[\"source_mask\"].to(config.DEVICE), \n",
    "        batch_inp[\"source_mask_tokens\"].to(config.DEVICE)\n",
    "    )\n",
    "\n",
    "    text_enc_last_h, learned_tokens = model._encode(\n",
    "        input_ids=input_ids, \n",
    "        attn_mask=attn_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        imgs=imgs    \n",
    "    )\n",
    "    \n",
    "    decoder_inp = torch.empty(1, 1, dtype=torch.long, device=input_ids.device).fill_(sos_token)\n",
    "\n",
    "    # decoding procedure\n",
    "    for t in range(max_len):\n",
    "        \n",
    "        decoder_mask = generate_causal_attention_mask(\n",
    "            dim=decoder_inp.shape[1]\n",
    "        ).type_as(attn_mask)\n",
    "        \n",
    "        # generate predictions\n",
    "        with torch.no_grad():\n",
    "            logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens = model._decode(\n",
    "            decoder_inp=decoder_inp, \n",
    "            encoder_outs=(text_enc_last_h, learned_tokens), \n",
    "            src_mask=src_mask, \n",
    "            target_mask=decoder_mask,\n",
    "            debug=debug,\n",
    "            return_actions=False\n",
    "        )\n",
    "\n",
    "        # perform greedy decoding\n",
    "        probs = model.decoder.action_generator(logits[:, -1])\n",
    "            \n",
    "        _, next_tok = torch.max(probs, dim=-1)\n",
    "        # update decoder input\n",
    "        decoder_inp = torch.cat((decoder_inp, next_tok.unsqueeze(1)), dim=1)\n",
    "            \n",
    "    return decoder_inp[:, 1:].cpu().detach(), logits, self_attn_ws.cpu().detach(), cross_attn_ws_seq.cpu().detach(), cross_attn_ws_tokens.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9aedb-5a52-48f6-b8df-d2cff2439aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(batch, model, loss_fn, debug:bool=False):\n",
    "    inp = fetch_sample_from_batch(\n",
    "        batch, \n",
    "        batch_size=batch[\"in_state\"].shape[0],\n",
    "        random=True\n",
    "    )\n",
    "    \n",
    "    pred_ids, logits, self_attn_ws, cross_attn_ws_seq, cross_attn_ws_tokens = greedy_decoding(\n",
    "        model=model, \n",
    "        batch_inp=inp, \n",
    "        debug=debug\n",
    "    )\n",
    "    \n",
    "    labels = inp[\"labels\"].to(config.DEVICE)\n",
    "    \n",
    "    preds = model.decode_predictions(\n",
    "            predicted_ids=pred_ids\n",
    "    )[0]\n",
    "\n",
    "    label = model.decode_predictions(\n",
    "        predicted_ids=labels\n",
    "    )[0]  \n",
    "    \n",
    "    # compute metrics\n",
    "    val_loss = loss_fn(logits.view(-1, logits.shape[2]), labels.view(-1)).item()  # loss\n",
    "    cer = model.cer_fn(preds, label).item() # Character Error Rate\n",
    "    wer = model.wer_fn(preds, label).item() # Word Error Rate\n",
    "    \n",
    "    output = {\n",
    "        \"val_loss\"              : val_loss,\n",
    "        \"CER\"                   : cer,\n",
    "        \"WER\"                   : wer,\n",
    "        \"label\"                 : label,\n",
    "        \"pred_ids\"              : pred_ids,\n",
    "        \"pred_tokens\"           : preds,\n",
    "        \"self_attn_ws\"          : self_attn_ws, \n",
    "        \"cross_attn_ws_seq\"     : cross_attn_ws_seq, \n",
    "        \"cross_attn_ws_tokens\"  : cross_attn_ws_tokens\n",
    "    }\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2be6db-be4c-415f-a56b-9158229cbe91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = validation_step(model=rt1, batch=batch, loss_fn=loss_fn)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8dbf5-0c21-40f9-ad2f-a7756961d03e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## üßëüèæ‚Äçüç≥ Prepare Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f24ee-c2cc-4cd3-bb87-e898490c0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, dm, opt, loss_fn, scheduler):\n",
    "    \n",
    "    loss_epoch = np.inf\n",
    "    val_loss = np.inf\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    cer_ = np.inf\n",
    "    wer_ = np.inf\n",
    "    \n",
    "    for e in range(config.EPOCHS):        \n",
    "        running_loss = 0.\n",
    "        num_steps = len(dm.train_dataloader())\n",
    "        \n",
    "        pbar = tqdm(\n",
    "            range(num_steps),\n",
    "            position=0,\n",
    "            leave=True,\n",
    "            dynamic_ncols=True,\n",
    "            total = num_steps\n",
    "        )\n",
    "        \n",
    "        # training\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dm.train_dataloader()):            \n",
    "            pct = 100. * step / num_steps\n",
    "            pbar.set_description(\n",
    "                f\"Epoch {e+1}/{config.EPOCHS} - (Train {pct:.1f}%)\"\n",
    "            )\n",
    "            pbar.update()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "\n",
    "            # training step\n",
    "            loss, logits, self_attn_ws, cross_attn_ws_seq, _ = training_step(\n",
    "                model=model, \n",
    "                batch=batch, \n",
    "                loss_fn=loss_fn\n",
    "            )\n",
    "            \n",
    "            # plot attention weights\n",
    "            plot_attention(\n",
    "                self_attn_ws, \n",
    "                show=False, \n",
    "                pre_fix=\"train_selfattn\", \n",
    "                folder=\"train\",\n",
    "                epoch=e,\n",
    "                wandb_logging=True\n",
    "            )\n",
    "\n",
    "            plot_attention(\n",
    "                cross_attn_ws_seq,\n",
    "                kind=\"cross\", \n",
    "                pre_fix=\"train_crossattn\", \n",
    "                show=False, \n",
    "                folder=\"train\",\n",
    "                epoch=e,\n",
    "                wandb_logging=True\n",
    "            )   \n",
    "            \n",
    "            running_loss += loss.item()         \n",
    "            \n",
    "            # logging\n",
    "            if step % 10 == 0:\n",
    "                pbar.set_postfix(\n",
    "                    train_loss_step=\"{:.04f}\".format(running_loss/(step+1)),\n",
    "                    train_loss=\"{:.04f}\".format(loss_epoch),\n",
    "                    CER=\"{:.04f}\".format(cer_),\n",
    "                    WER=\"{:.04f}\".format(wer_),\n",
    "                    val_loss=\"{:.04f}\".format(val_loss),\n",
    "                )\n",
    "                pbar.update()\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # Adjust learning weights\n",
    "            opt.step()\n",
    "            \n",
    "        loss_epoch = running_loss / len(dm.train_dataloader())   \n",
    "        final_lr_epoch = float(opt.param_groups[0]['lr'])\n",
    "        \n",
    "        # predictions\n",
    "        preds = logits.softmax(dim=-1).argmax(dim=-1)\n",
    "\n",
    "        # decode predictions\n",
    "        preds = model.decode_predictions(\n",
    "            predicted_ids=preds\n",
    "        )\n",
    "\n",
    "        labels = model.decode_predictions(\n",
    "            predicted_ids=batch[\"motor_cmd\"][\"labels\"]\n",
    "        )         \n",
    "            \n",
    "        # log decoded sentenses\n",
    "        with open(config.LOGGING_FILE, \"a\") as f:            \n",
    "            f.write(f\"Epoch #{e+1}\\n\")\n",
    "            f.write(f\"[Train] \\n\")\n",
    "            \n",
    "            pred = preds[0]\n",
    "            label = labels[0]\n",
    "            \n",
    "            cer_ = model.cer_fn(pred, label).item()\n",
    "            wer_ = model.wer_fn(pred, label).item()\n",
    "            f.write(f\"Predicted \\t: {pred}\\n\")\n",
    "            f.write(f\"Actual \\t\\t: {label}\\n\")\n",
    "                \n",
    "        # validation\n",
    "        out = validation_step(model=rt1, batch=batch, loss_fn=loss_fn)\n",
    "        val_loss = out[\"val_loss\"]\n",
    "        \n",
    "        # start scheduling lr after epoch X\n",
    "        # X set to 30 to start us of\n",
    "        if e >=30:\n",
    "            scheduler.step(val_loss)\n",
    "       \n",
    "        # plot attention weights\n",
    "        plot_attention(\n",
    "            out[\"self_attn_ws\"], \n",
    "            show=False, \n",
    "            pre_fix=\"val_selfattn\", \n",
    "            folder=\"val\",\n",
    "            epoch=e,\n",
    "            wandb_logging=True\n",
    "        )\n",
    "\n",
    "        plot_attention(\n",
    "            out[\"cross_attn_ws_seq\"],\n",
    "            kind=\"cross\", \n",
    "            pre_fix=\"val_crossattn\", \n",
    "            show=False, \n",
    "            folder=\"val\",\n",
    "            epoch=e,\n",
    "            wandb_logging=True\n",
    "        )   \n",
    "\n",
    "        # plot_attention(\n",
    "        #     out[\"cross_attn_ws_tokens\"], \n",
    "        #     pre_fix=\"val_crossattn_tokens\", \n",
    "        #     show=False, \n",
    "        #     folder=\"val\",\n",
    "        #     epoch=e,\n",
    "        #     wandb_logging=True\n",
    "        # )   \n",
    "        \n",
    "        # update best score\n",
    "        if val_loss < best_val_loss:\n",
    "            # save checkpoint\n",
    "            path = os.path.join(config.MODEL_PATH, \"be_model.bin\")\n",
    "            torch.save({\n",
    "                'model_state_dict'      :model.state_dict(),\n",
    "                'optimizer_state_dict'  :opt.state_dict(),\n",
    "                'val_loss'              : val_loss, \n",
    "                'epoch'                 : e\n",
    "                }, path)\n",
    "            \n",
    "            # update best score\n",
    "            best_val_loss = val_loss        \n",
    "        \n",
    "        pbar.set_postfix(\n",
    "            train_loss_step=\"{:.04f}\".format(running_loss/(step+1)),\n",
    "            train_loss=\"{:.04f}\".format(loss_epoch),\n",
    "            # CER=\"{:.04f}\".format(cer_),\n",
    "            # WER=\"{:.04f}\".format(wer_),\n",
    "            val_Loss=\"{:.04f}\".format(val_loss),\n",
    "            val_CER=\"{:.04f}\".format(out[\"CER\"]),\n",
    "            val_WER=\"{:.04f}\".format(out[\"WER\"]),\n",
    "            lr_epoch=\"{:.1e}\".format(final_lr_epoch),\n",
    "        )  \n",
    "        pbar.update()\n",
    "        \n",
    "        logs_dict = {\n",
    "            \"epoch\" :e,\n",
    "            \"train_loss\":loss_epoch,\n",
    "            \"val_loss\":val_loss,\n",
    "            \"val_CER\":out[\"CER\"],\n",
    "            \"valWER\":out[\"WER\"],\n",
    "            \"lr\":final_lr_epoch\n",
    "        }\n",
    "        wandb.log(logs_dict)\n",
    "        \n",
    "        # log decoded sentenses\n",
    "        with open(config.LOGGING_FILE, \"a\") as f:                        \n",
    "            pred = out[\"pred_tokens\"]\n",
    "            label = out[\"label\"]\n",
    "            \n",
    "            f.write(f\"[Val] \\n\")            \n",
    "            f.write(f\"Predicted \\t: {pred}\\n\")\n",
    "            f.write(f\"Actual \\t\\t: {label}\\n\") \n",
    "            f.write(f\"Curr val loss \\t\\t: {val_loss:.5f}\\n\") \n",
    "            f.write(f\"Best loss: \\t\\t: {best_val_loss:.5f}\\n\\n\") \n",
    "            \n",
    "        pbar.close()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffd0fb-8dcb-4d92-b2e9-72be3348c68d",
   "metadata": {},
   "source": [
    "## üöÄ Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b805dc-8fe1-4324-a3aa-89ad21471aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "\n",
    "random.seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(config.SEED)\n",
    "    torch.cuda.manual_seed_all(config.SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a5ef6-3a47-4c74-870d-7e10937009b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### init experiment\n",
    "run = wandb.init(\n",
    "    project='SMF-Be', \n",
    "    group=\"RT1-CRAM\", \n",
    "    name=\"be_model\", \n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "with open(config.LOGGING_FILE, \"a\") as f:   \n",
    "    f.write(\"*** New experiment ***\\n\")\n",
    "    \n",
    "    \n",
    "trained_model = run_experiment(\n",
    "    model=rt1, \n",
    "    dm=dm, \n",
    "    opt=opt, \n",
    "    loss_fn=loss_fn,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa000104-cc3b-4927-ae6e-b7ec8745e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac23076-a4a3-459a-b714-eb4ad052fbb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üë®üèø‚Äçüî¨ Test / Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c8ac-54da-4758-9382-a7e0c8ec8294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9c86c-0345-4fe7-b85b-07cdb971a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids=batch[\"action_desc\"][\"ids\"].cuda()\n",
    "# attn_mask=batch[\"action_desc\"][\"mask\"].cuda()\n",
    "# token_type_ids=batch[\"action_desc\"][\"token_type_ids\"].cuda()\n",
    "# imgs=batch[\"in_state\"].cuda()\n",
    "# decoder_inp=batch[\"motor_cmd\"][\"decoder_inp_ids\"].cuda()\n",
    "# src_mask=(batch[\"source_mask\"].cuda(), batch[\"source_mask_tokens\"].cuda())\n",
    "# target_mask=batch[\"target_mask\"].cuda()\n",
    "# labels = batch[\"motor_cmd\"][\"labels\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2c917-08ae-444c-a456-fd3ace430e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed396280-b161-4b1f-b8b6-0801e3786cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0a9f9-42d6-4905-bc84-c23b468c7c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246745c7-2958-493c-90b9-94e77b0b85b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMF-BE",
   "language": "python",
   "name": "smf-be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
